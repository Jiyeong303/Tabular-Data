{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b62467d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 12:14:49.834520: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier 학습중...\n",
      "Voting Classifier 저장\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 12:37:28.086562: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-06-23 12:37:28.087221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:37:28.088034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:10:00.0 name: NVIDIA GeForce RTX 2070 SUPER computeCapability: 7.5\n",
      "coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2022-06-23 12:37:28.088139: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-06-23 12:37:28.098617: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-06-23 12:37:28.098680: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-06-23 12:37:28.102673: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-06-23 12:37:28.105312: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-06-23 12:37:28.106732: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-06-23 12:37:28.108420: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-06-23 12:37:28.108868: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-06-23 12:37:28.109241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:37:28.109994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:37:28.110288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-06-23 12:37:28.110990: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-23 12:37:28.112681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:37:28.113433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:10:00.0 name: NVIDIA GeForce RTX 2070 SUPER computeCapability: 7.5\n",
      "coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2022-06-23 12:37:28.113837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:37:28.114154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:37:28.114392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-06-23 12:37:28.114543: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-06-23 12:37:28.612556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-06-23 12:37:28.612598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-06-23 12:37:28.612603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-06-23 12:37:28.612854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:37:28.613463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:37:28.613773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:37:28.614047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4743 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:10:00.0, compute capability: 7.5)\n",
      "2022-06-23 12:37:29.151170: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-06-23 12:37:29.169159: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3600255000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 12:37:30.025798: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-06-23 12:37:30.501484: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8204\n",
      "2022-06-23 12:37:30.983116: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-06-23 12:37:31.402755: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 20s 24ms/step - loss: 1.2827 - accuracy: 0.4147 - val_loss: 1.3438 - val_accuracy: 0.3976\n",
      "Epoch 2/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 1.1657 - accuracy: 0.4844 - val_loss: 1.2809 - val_accuracy: 0.4619\n",
      "Epoch 3/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 1.0993 - accuracy: 0.5280 - val_loss: 1.1493 - val_accuracy: 0.5048\n",
      "Epoch 4/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 1.0250 - accuracy: 0.5727 - val_loss: 1.0219 - val_accuracy: 0.5786\n",
      "Epoch 5/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.9483 - accuracy: 0.6187 - val_loss: 0.9861 - val_accuracy: 0.6190\n",
      "Epoch 6/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.8766 - accuracy: 0.6556 - val_loss: 0.8278 - val_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.8170 - accuracy: 0.6861 - val_loss: 0.7591 - val_accuracy: 0.7024\n",
      "Epoch 8/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.7598 - accuracy: 0.7124 - val_loss: 0.7390 - val_accuracy: 0.7190\n",
      "Epoch 9/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.7122 - accuracy: 0.7343 - val_loss: 0.6607 - val_accuracy: 0.7452\n",
      "Epoch 10/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.6758 - accuracy: 0.7534 - val_loss: 0.6351 - val_accuracy: 0.7667\n",
      "Epoch 11/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.6387 - accuracy: 0.7719 - val_loss: 0.6214 - val_accuracy: 0.7667\n",
      "Epoch 12/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.6087 - accuracy: 0.7828 - val_loss: 0.5789 - val_accuracy: 0.7714\n",
      "Epoch 13/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.5808 - accuracy: 0.7947 - val_loss: 0.5791 - val_accuracy: 0.7905\n",
      "Epoch 14/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.5587 - accuracy: 0.8040 - val_loss: 0.5878 - val_accuracy: 0.7952\n",
      "Epoch 15/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.5392 - accuracy: 0.8123 - val_loss: 0.5440 - val_accuracy: 0.8048\n",
      "Epoch 16/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.5167 - accuracy: 0.8236 - val_loss: 0.5324 - val_accuracy: 0.8167\n",
      "Epoch 17/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4991 - accuracy: 0.8286 - val_loss: 0.5408 - val_accuracy: 0.8119\n",
      "Epoch 18/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4819 - accuracy: 0.8361 - val_loss: 0.5166 - val_accuracy: 0.8119\n",
      "Epoch 19/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4654 - accuracy: 0.8421 - val_loss: 0.5091 - val_accuracy: 0.8167\n",
      "Epoch 20/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4536 - accuracy: 0.8464 - val_loss: 0.5420 - val_accuracy: 0.8476\n",
      "Epoch 21/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4365 - accuracy: 0.8525 - val_loss: 0.5581 - val_accuracy: 0.8333\n",
      "Epoch 22/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4309 - accuracy: 0.8563 - val_loss: 0.4989 - val_accuracy: 0.8405\n",
      "Epoch 23/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4133 - accuracy: 0.8618 - val_loss: 0.5504 - val_accuracy: 0.8429\n",
      "Epoch 24/1000\n",
      "703/703 [==============================] - 14s 21ms/step - loss: 0.4049 - accuracy: 0.8651 - val_loss: 0.4980 - val_accuracy: 0.8619\n",
      "Epoch 25/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3952 - accuracy: 0.8691 - val_loss: 0.4818 - val_accuracy: 0.8643\n",
      "Epoch 26/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3832 - accuracy: 0.8730 - val_loss: 0.5305 - val_accuracy: 0.8571\n",
      "Epoch 27/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3752 - accuracy: 0.8768 - val_loss: 0.5678 - val_accuracy: 0.8571\n",
      "Epoch 28/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3702 - accuracy: 0.8781 - val_loss: 0.5385 - val_accuracy: 0.8476\n",
      "Epoch 29/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3625 - accuracy: 0.8810 - val_loss: 0.4963 - val_accuracy: 0.8548\n",
      "Epoch 30/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3538 - accuracy: 0.8850 - val_loss: 0.5255 - val_accuracy: 0.8500\n",
      "Epoch 31/1000\n",
      "703/703 [==============================] - 14s 21ms/step - loss: 0.3479 - accuracy: 0.8856 - val_loss: 0.5161 - val_accuracy: 0.8476\n",
      "Epoch 32/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3428 - accuracy: 0.8877 - val_loss: 0.5125 - val_accuracy: 0.8548\n",
      "Epoch 33/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3318 - accuracy: 0.8916 - val_loss: 0.4726 - val_accuracy: 0.8429\n",
      "Epoch 34/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3278 - accuracy: 0.8940 - val_loss: 0.4644 - val_accuracy: 0.8548\n",
      "Epoch 35/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3272 - accuracy: 0.8942 - val_loss: 0.5075 - val_accuracy: 0.8595\n",
      "Epoch 36/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3182 - accuracy: 0.8970 - val_loss: 0.4985 - val_accuracy: 0.8571\n",
      "Epoch 37/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3138 - accuracy: 0.8985 - val_loss: 0.5092 - val_accuracy: 0.8571\n",
      "Epoch 38/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3132 - accuracy: 0.8996 - val_loss: 0.5313 - val_accuracy: 0.8667\n",
      "Epoch 39/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3028 - accuracy: 0.9021 - val_loss: 0.4984 - val_accuracy: 0.8690\n",
      "Epoch 40/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3005 - accuracy: 0.9028 - val_loss: 0.4856 - val_accuracy: 0.8714\n",
      "Epoch 41/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2934 - accuracy: 0.9055 - val_loss: 0.5052 - val_accuracy: 0.8667\n",
      "Epoch 42/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2900 - accuracy: 0.9072 - val_loss: 0.5172 - val_accuracy: 0.8643\n",
      "Epoch 43/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2834 - accuracy: 0.9086 - val_loss: 0.5122 - val_accuracy: 0.8714\n",
      "Epoch 44/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2843 - accuracy: 0.9082 - val_loss: 0.4756 - val_accuracy: 0.8786\n",
      "Epoch 45/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2842 - accuracy: 0.9088 - val_loss: 0.5663 - val_accuracy: 0.8762\n",
      "Epoch 46/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2744 - accuracy: 0.9128 - val_loss: 0.4801 - val_accuracy: 0.8714\n",
      "Epoch 47/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2696 - accuracy: 0.9134 - val_loss: 0.5476 - val_accuracy: 0.8738\n",
      "Epoch 48/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2695 - accuracy: 0.9135 - val_loss: 0.5273 - val_accuracy: 0.8619\n",
      "Epoch 49/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2632 - accuracy: 0.9175 - val_loss: 0.5281 - val_accuracy: 0.8762\n",
      "Epoch 50/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2640 - accuracy: 0.9154 - val_loss: 0.5216 - val_accuracy: 0.8690\n",
      "Epoch 51/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2600 - accuracy: 0.9179 - val_loss: 0.5085 - val_accuracy: 0.8548\n",
      "Epoch 52/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2548 - accuracy: 0.9192 - val_loss: 0.4903 - val_accuracy: 0.8690\n",
      "Epoch 53/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2561 - accuracy: 0.9184 - val_loss: 0.4681 - val_accuracy: 0.8714\n",
      "Epoch 54/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2532 - accuracy: 0.9189 - val_loss: 0.4937 - val_accuracy: 0.8738\n",
      "Epoch 55/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2502 - accuracy: 0.9202 - val_loss: 0.5337 - val_accuracy: 0.8667\n",
      "Epoch 56/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2476 - accuracy: 0.9223 - val_loss: 0.5342 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2499 - accuracy: 0.9208 - val_loss: 0.5426 - val_accuracy: 0.8714\n",
      "Epoch 58/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2465 - accuracy: 0.9216 - val_loss: 0.4543 - val_accuracy: 0.8857\n",
      "Epoch 59/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2452 - accuracy: 0.9232 - val_loss: 0.5105 - val_accuracy: 0.8714\n",
      "Epoch 60/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2361 - accuracy: 0.9252 - val_loss: 0.5443 - val_accuracy: 0.8643\n",
      "Epoch 61/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2339 - accuracy: 0.9264 - val_loss: 0.4899 - val_accuracy: 0.8833\n",
      "Epoch 62/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2357 - accuracy: 0.9256 - val_loss: 0.5569 - val_accuracy: 0.8667\n",
      "Epoch 63/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2335 - accuracy: 0.9267 - val_loss: 0.5350 - val_accuracy: 0.8738\n",
      "Epoch 64/1000\n",
      "703/703 [==============================] - 14s 21ms/step - loss: 0.2328 - accuracy: 0.9272 - val_loss: 0.5297 - val_accuracy: 0.8667\n",
      "Epoch 65/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2299 - accuracy: 0.9276 - val_loss: 0.5422 - val_accuracy: 0.8714\n",
      "Epoch 66/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2305 - accuracy: 0.9276 - val_loss: 0.5210 - val_accuracy: 0.8667\n",
      "Epoch 67/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2273 - accuracy: 0.9279 - val_loss: 0.5398 - val_accuracy: 0.8714\n",
      "Epoch 68/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2224 - accuracy: 0.9294 - val_loss: 0.5573 - val_accuracy: 0.8667\n",
      "Epoch 69/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2250 - accuracy: 0.9286 - val_loss: 0.5345 - val_accuracy: 0.8738\n",
      "Epoch 70/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2227 - accuracy: 0.9306 - val_loss: 0.5073 - val_accuracy: 0.8690\n",
      "Epoch 71/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2168 - accuracy: 0.9310 - val_loss: 0.5681 - val_accuracy: 0.8643\n",
      "Epoch 72/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2236 - accuracy: 0.9293 - val_loss: 0.5282 - val_accuracy: 0.8714\n",
      "Epoch 73/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2125 - accuracy: 0.9336 - val_loss: 0.5068 - val_accuracy: 0.8714\n",
      "Epoch 74/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.2155 - accuracy: 0.9333 - val_loss: 0.4770 - val_accuracy: 0.8643\n",
      "Epoch 75/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.2144 - accuracy: 0.9330 - val_loss: 0.5680 - val_accuracy: 0.8714\n",
      "Epoch 76/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.2149 - accuracy: 0.9321 - val_loss: 0.4968 - val_accuracy: 0.8738\n",
      "Epoch 77/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2089 - accuracy: 0.9349 - val_loss: 0.5665 - val_accuracy: 0.8595\n",
      "Epoch 78/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.2109 - accuracy: 0.9339 - val_loss: 0.5855 - val_accuracy: 0.8619\n",
      "Epoch 79/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1874 - accuracy: 0.9426 - val_loss: 0.5178 - val_accuracy: 0.8643\n",
      "Epoch 80/1000\n",
      "703/703 [==============================] - 14s 21ms/step - loss: 0.1782 - accuracy: 0.9451 - val_loss: 0.5510 - val_accuracy: 0.8690\n",
      "Epoch 81/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1767 - accuracy: 0.9455 - val_loss: 0.5255 - val_accuracy: 0.8738\n",
      "Epoch 82/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1721 - accuracy: 0.9465 - val_loss: 0.5329 - val_accuracy: 0.8690\n",
      "Epoch 83/1000\n",
      "703/703 [==============================] - 14s 21ms/step - loss: 0.1691 - accuracy: 0.9472 - val_loss: 0.5698 - val_accuracy: 0.8690\n",
      "Epoch 84/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1674 - accuracy: 0.9483 - val_loss: 0.5352 - val_accuracy: 0.8810\n",
      "Epoch 85/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1671 - accuracy: 0.9468 - val_loss: 0.5332 - val_accuracy: 0.8762\n",
      "Epoch 86/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1640 - accuracy: 0.9491 - val_loss: 0.5289 - val_accuracy: 0.8762\n",
      "Epoch 87/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1621 - accuracy: 0.9496 - val_loss: 0.5174 - val_accuracy: 0.8738\n",
      "Epoch 88/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.1627 - accuracy: 0.9505 - val_loss: 0.5172 - val_accuracy: 0.8714\n",
      "Epoch 89/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1591 - accuracy: 0.9506 - val_loss: 0.5500 - val_accuracy: 0.8714\n",
      "Epoch 90/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1590 - accuracy: 0.9505 - val_loss: 0.5402 - val_accuracy: 0.8714\n",
      "Epoch 91/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1571 - accuracy: 0.9518 - val_loss: 0.5787 - val_accuracy: 0.8714\n",
      "Epoch 92/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1583 - accuracy: 0.9511 - val_loss: 0.5515 - val_accuracy: 0.8690\n",
      "Epoch 93/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1566 - accuracy: 0.9514 - val_loss: 0.5514 - val_accuracy: 0.8762\n",
      "Epoch 94/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1555 - accuracy: 0.9523 - val_loss: 0.5328 - val_accuracy: 0.8714\n",
      "Epoch 95/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1512 - accuracy: 0.9524 - val_loss: 0.5252 - val_accuracy: 0.8786\n",
      "Epoch 96/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1480 - accuracy: 0.9549 - val_loss: 0.5857 - val_accuracy: 0.8762\n",
      "Epoch 97/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1511 - accuracy: 0.9533 - val_loss: 0.5910 - val_accuracy: 0.8667\n",
      "Epoch 98/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1498 - accuracy: 0.9544 - val_loss: 0.5680 - val_accuracy: 0.8833\n",
      "Epoch 99/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1432 - accuracy: 0.9560 - val_loss: 0.5867 - val_accuracy: 0.8762\n",
      "Epoch 100/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1358 - accuracy: 0.9578 - val_loss: 0.5744 - val_accuracy: 0.8738\n",
      "Epoch 101/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1360 - accuracy: 0.9583 - val_loss: 0.5966 - val_accuracy: 0.8810\n",
      "Epoch 102/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1340 - accuracy: 0.9586 - val_loss: 0.5957 - val_accuracy: 0.8690\n",
      "Epoch 103/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1296 - accuracy: 0.9601 - val_loss: 0.5676 - val_accuracy: 0.8762\n",
      "Epoch 104/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1311 - accuracy: 0.9602 - val_loss: 0.5560 - val_accuracy: 0.8762\n",
      "Epoch 105/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1323 - accuracy: 0.9592 - val_loss: 0.5327 - val_accuracy: 0.8714\n",
      "Epoch 106/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1310 - accuracy: 0.9595 - val_loss: 0.5319 - val_accuracy: 0.8810\n",
      "Epoch 107/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1305 - accuracy: 0.9601 - val_loss: 0.5683 - val_accuracy: 0.8786\n",
      "Epoch 108/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1257 - accuracy: 0.9604 - val_loss: 0.5564 - val_accuracy: 0.8786\n",
      "Epoch 109/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1284 - accuracy: 0.9608 - val_loss: 0.5517 - val_accuracy: 0.8714\n",
      "Epoch 110/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1284 - accuracy: 0.9607 - val_loss: 0.5659 - val_accuracy: 0.8738\n",
      "Epoch 111/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1225 - accuracy: 0.9617 - val_loss: 0.5538 - val_accuracy: 0.8762\n",
      "Epoch 112/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1248 - accuracy: 0.9622 - val_loss: 0.5575 - val_accuracy: 0.8762\n",
      "Epoch 113/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1266 - accuracy: 0.9610 - val_loss: 0.5515 - val_accuracy: 0.8738\n",
      "Epoch 114/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1234 - accuracy: 0.9617 - val_loss: 0.5620 - val_accuracy: 0.8833\n",
      "Epoch 115/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1237 - accuracy: 0.9620 - val_loss: 0.5429 - val_accuracy: 0.8714\n",
      "Epoch 116/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1257 - accuracy: 0.9612 - val_loss: 0.5493 - val_accuracy: 0.8762\n",
      "Epoch 117/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1269 - accuracy: 0.9615 - val_loss: 0.5307 - val_accuracy: 0.8786\n",
      "Epoch 118/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1231 - accuracy: 0.9616 - val_loss: 0.5717 - val_accuracy: 0.8714\n",
      "Epoch 119/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1200 - accuracy: 0.9634 - val_loss: 0.5703 - val_accuracy: 0.8762\n",
      "Epoch 120/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1170 - accuracy: 0.9645 - val_loss: 0.5732 - val_accuracy: 0.8810\n",
      "Epoch 121/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1144 - accuracy: 0.9647 - val_loss: 0.5863 - val_accuracy: 0.8786\n",
      "Epoch 122/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1156 - accuracy: 0.9645 - val_loss: 0.5897 - val_accuracy: 0.8762\n",
      "Epoch 123/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1127 - accuracy: 0.9647 - val_loss: 0.6046 - val_accuracy: 0.8714\n",
      "Epoch 124/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1156 - accuracy: 0.9649 - val_loss: 0.5520 - val_accuracy: 0.8762\n",
      "Epoch 125/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1137 - accuracy: 0.9652 - val_loss: 0.5965 - val_accuracy: 0.8714\n",
      "Epoch 126/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1126 - accuracy: 0.9648 - val_loss: 0.5770 - val_accuracy: 0.8810\n",
      "Epoch 127/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1131 - accuracy: 0.9654 - val_loss: 0.5799 - val_accuracy: 0.8786\n",
      "Epoch 128/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1113 - accuracy: 0.9651 - val_loss: 0.5946 - val_accuracy: 0.8762\n",
      "Epoch 129/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1118 - accuracy: 0.9659 - val_loss: 0.5699 - val_accuracy: 0.8762\n",
      "Epoch 130/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1143 - accuracy: 0.9643 - val_loss: 0.5640 - val_accuracy: 0.8786\n",
      "Epoch 131/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1118 - accuracy: 0.9654 - val_loss: 0.5859 - val_accuracy: 0.8786\n",
      "Epoch 132/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1101 - accuracy: 0.9661 - val_loss: 0.5910 - val_accuracy: 0.8786\n",
      "Epoch 133/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1130 - accuracy: 0.9651 - val_loss: 0.5735 - val_accuracy: 0.8786\n",
      "Epoch 00133: early stopping\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.5735 - accuracy: 0.8786\n",
      "model_1 loss : [0.5734580159187317, 0.8785714507102966]\n",
      "Epoch 1/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1416 - accuracy: 0.9590 - val_loss: 0.4338 - val_accuracy: 0.8881\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1386 - accuracy: 0.9587 - val_loss: 0.3808 - val_accuracy: 0.8881\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1362 - accuracy: 0.9591 - val_loss: 0.3339 - val_accuracy: 0.9048\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1369 - accuracy: 0.9590 - val_loss: 0.2835 - val_accuracy: 0.9119\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1368 - accuracy: 0.9598 - val_loss: 0.2761 - val_accuracy: 0.9190\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1346 - accuracy: 0.9602 - val_loss: 0.2431 - val_accuracy: 0.9214\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1294 - accuracy: 0.9598 - val_loss: 0.2407 - val_accuracy: 0.9214\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1321 - accuracy: 0.9597 - val_loss: 0.2104 - val_accuracy: 0.9310\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1300 - accuracy: 0.9601 - val_loss: 0.2150 - val_accuracy: 0.9286\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1290 - accuracy: 0.9617 - val_loss: 0.1955 - val_accuracy: 0.9333\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1277 - accuracy: 0.9610 - val_loss: 0.1968 - val_accuracy: 0.9357\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1293 - accuracy: 0.9614 - val_loss: 0.1752 - val_accuracy: 0.9357\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1255 - accuracy: 0.9620 - val_loss: 0.1807 - val_accuracy: 0.9405\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1269 - accuracy: 0.9615 - val_loss: 0.1611 - val_accuracy: 0.9381\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1272 - accuracy: 0.9610 - val_loss: 0.1529 - val_accuracy: 0.9452\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1253 - accuracy: 0.9611 - val_loss: 0.1534 - val_accuracy: 0.9405\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1244 - accuracy: 0.9619 - val_loss: 0.1409 - val_accuracy: 0.9405\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1214 - accuracy: 0.9631 - val_loss: 0.1412 - val_accuracy: 0.9381\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1258 - accuracy: 0.9625 - val_loss: 0.1386 - val_accuracy: 0.9381\n",
      "Epoch 20/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1226 - accuracy: 0.9618 - val_loss: 0.1357 - val_accuracy: 0.9452\n",
      "Epoch 21/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1217 - accuracy: 0.9629 - val_loss: 0.1284 - val_accuracy: 0.9476\n",
      "Epoch 22/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1220 - accuracy: 0.9623 - val_loss: 0.1300 - val_accuracy: 0.9500\n",
      "Epoch 23/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1211 - accuracy: 0.9625 - val_loss: 0.1245 - val_accuracy: 0.9476\n",
      "Epoch 24/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1221 - accuracy: 0.9630 - val_loss: 0.1277 - val_accuracy: 0.9548\n",
      "Epoch 25/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1190 - accuracy: 0.9631 - val_loss: 0.1228 - val_accuracy: 0.9548\n",
      "Epoch 26/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1184 - accuracy: 0.9638 - val_loss: 0.1227 - val_accuracy: 0.9595\n",
      "Epoch 27/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1222 - accuracy: 0.9632 - val_loss: 0.1141 - val_accuracy: 0.9619\n",
      "Epoch 28/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1200 - accuracy: 0.9636 - val_loss: 0.1155 - val_accuracy: 0.9595\n",
      "Epoch 29/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1208 - accuracy: 0.9626 - val_loss: 0.1208 - val_accuracy: 0.9548\n",
      "Epoch 30/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1176 - accuracy: 0.9645 - val_loss: 0.1139 - val_accuracy: 0.9571\n",
      "Epoch 31/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1182 - accuracy: 0.9632 - val_loss: 0.1177 - val_accuracy: 0.9667\n",
      "Epoch 32/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1161 - accuracy: 0.9640 - val_loss: 0.1190 - val_accuracy: 0.9619\n",
      "Epoch 33/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1177 - accuracy: 0.9639 - val_loss: 0.1052 - val_accuracy: 0.9571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1175 - accuracy: 0.9638 - val_loss: 0.1033 - val_accuracy: 0.9571\n",
      "Epoch 35/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1178 - accuracy: 0.9645 - val_loss: 0.0999 - val_accuracy: 0.9595\n",
      "Epoch 36/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1156 - accuracy: 0.9646 - val_loss: 0.1013 - val_accuracy: 0.9619\n",
      "Epoch 37/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1128 - accuracy: 0.9647 - val_loss: 0.0964 - val_accuracy: 0.9619\n",
      "Epoch 38/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1135 - accuracy: 0.9656 - val_loss: 0.0978 - val_accuracy: 0.9643\n",
      "Epoch 39/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1147 - accuracy: 0.9643 - val_loss: 0.0982 - val_accuracy: 0.9595\n",
      "Epoch 40/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1155 - accuracy: 0.9653 - val_loss: 0.1042 - val_accuracy: 0.9619\n",
      "Epoch 41/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1152 - accuracy: 0.9646 - val_loss: 0.1015 - val_accuracy: 0.9595\n",
      "Epoch 42/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1121 - accuracy: 0.9649 - val_loss: 0.0957 - val_accuracy: 0.9643\n",
      "Epoch 43/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1153 - accuracy: 0.9647 - val_loss: 0.0899 - val_accuracy: 0.9643\n",
      "Epoch 44/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1111 - accuracy: 0.9655 - val_loss: 0.0932 - val_accuracy: 0.9690\n",
      "Epoch 45/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1154 - accuracy: 0.9644 - val_loss: 0.0827 - val_accuracy: 0.9690\n",
      "Epoch 46/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1138 - accuracy: 0.9649 - val_loss: 0.0805 - val_accuracy: 0.9690\n",
      "Epoch 47/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1149 - accuracy: 0.9645 - val_loss: 0.0856 - val_accuracy: 0.9667\n",
      "Epoch 48/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1115 - accuracy: 0.9663 - val_loss: 0.0824 - val_accuracy: 0.9667\n",
      "Epoch 49/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1098 - accuracy: 0.9652 - val_loss: 0.0841 - val_accuracy: 0.9690\n",
      "Epoch 50/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1103 - accuracy: 0.9669 - val_loss: 0.0821 - val_accuracy: 0.9690\n",
      "Epoch 51/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1102 - accuracy: 0.9656 - val_loss: 0.0745 - val_accuracy: 0.9690\n",
      "Epoch 52/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1127 - accuracy: 0.9660 - val_loss: 0.0762 - val_accuracy: 0.9690\n",
      "Epoch 53/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1084 - accuracy: 0.9675 - val_loss: 0.0780 - val_accuracy: 0.9714\n",
      "Epoch 54/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1094 - accuracy: 0.9658 - val_loss: 0.0754 - val_accuracy: 0.9690\n",
      "Epoch 55/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1117 - accuracy: 0.9653 - val_loss: 0.0771 - val_accuracy: 0.9667\n",
      "Epoch 56/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1099 - accuracy: 0.9664 - val_loss: 0.0827 - val_accuracy: 0.9714\n",
      "Epoch 57/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1107 - accuracy: 0.9667 - val_loss: 0.0750 - val_accuracy: 0.9714\n",
      "Epoch 58/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1115 - accuracy: 0.9662 - val_loss: 0.0746 - val_accuracy: 0.9667\n",
      "Epoch 59/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1080 - accuracy: 0.9669 - val_loss: 0.0754 - val_accuracy: 0.9714\n",
      "Epoch 60/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1091 - accuracy: 0.9660 - val_loss: 0.0703 - val_accuracy: 0.9690\n",
      "Epoch 61/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1105 - accuracy: 0.9659 - val_loss: 0.0698 - val_accuracy: 0.9619\n",
      "Epoch 62/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1103 - accuracy: 0.9662 - val_loss: 0.0661 - val_accuracy: 0.9738\n",
      "Epoch 63/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1070 - accuracy: 0.9668 - val_loss: 0.0735 - val_accuracy: 0.9714\n",
      "Epoch 64/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1069 - accuracy: 0.9672 - val_loss: 0.0677 - val_accuracy: 0.9714\n",
      "Epoch 65/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1052 - accuracy: 0.9675 - val_loss: 0.0646 - val_accuracy: 0.9714\n",
      "Epoch 66/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1067 - accuracy: 0.9671 - val_loss: 0.0726 - val_accuracy: 0.9738\n",
      "Epoch 67/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1077 - accuracy: 0.9674 - val_loss: 0.0707 - val_accuracy: 0.9714\n",
      "Epoch 68/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1088 - accuracy: 0.9671 - val_loss: 0.0701 - val_accuracy: 0.9738\n",
      "Epoch 69/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1027 - accuracy: 0.9687 - val_loss: 0.0640 - val_accuracy: 0.9762\n",
      "Epoch 70/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1054 - accuracy: 0.9671 - val_loss: 0.0580 - val_accuracy: 0.9786\n",
      "Epoch 71/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1040 - accuracy: 0.9681 - val_loss: 0.0653 - val_accuracy: 0.9762\n",
      "Epoch 72/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1064 - accuracy: 0.9676 - val_loss: 0.0661 - val_accuracy: 0.9738\n",
      "Epoch 73/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1047 - accuracy: 0.9672 - val_loss: 0.0631 - val_accuracy: 0.9738\n",
      "Epoch 74/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1041 - accuracy: 0.9673 - val_loss: 0.0643 - val_accuracy: 0.9738\n",
      "Epoch 75/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1052 - accuracy: 0.9673 - val_loss: 0.0647 - val_accuracy: 0.9762\n",
      "Epoch 76/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1008 - accuracy: 0.9683 - val_loss: 0.0601 - val_accuracy: 0.9786\n",
      "Epoch 77/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1029 - accuracy: 0.9689 - val_loss: 0.0566 - val_accuracy: 0.9810\n",
      "Epoch 78/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1048 - accuracy: 0.9678 - val_loss: 0.0553 - val_accuracy: 0.9786\n",
      "Epoch 79/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1015 - accuracy: 0.9680 - val_loss: 0.0527 - val_accuracy: 0.9786\n",
      "Epoch 80/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1037 - accuracy: 0.9685 - val_loss: 0.0553 - val_accuracy: 0.9786\n",
      "Epoch 81/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1043 - accuracy: 0.9681 - val_loss: 0.0556 - val_accuracy: 0.9786\n",
      "Epoch 82/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1032 - accuracy: 0.9682 - val_loss: 0.0506 - val_accuracy: 0.9810\n",
      "Epoch 83/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1005 - accuracy: 0.9685 - val_loss: 0.0529 - val_accuracy: 0.9833\n",
      "Epoch 84/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1050 - accuracy: 0.9677 - val_loss: 0.0506 - val_accuracy: 0.9810\n",
      "Epoch 85/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1015 - accuracy: 0.9684 - val_loss: 0.0520 - val_accuracy: 0.9786\n",
      "Epoch 86/100\n",
      "704/704 [==============================] - 17s 25ms/step - loss: 0.0993 - accuracy: 0.9687 - val_loss: 0.0507 - val_accuracy: 0.9833\n",
      "Epoch 87/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.0999 - accuracy: 0.9690 - val_loss: 0.0460 - val_accuracy: 0.9810\n",
      "Epoch 88/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1037 - accuracy: 0.9685 - val_loss: 0.0460 - val_accuracy: 0.9833\n",
      "Epoch 89/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1049 - accuracy: 0.9685 - val_loss: 0.0512 - val_accuracy: 0.9810\n",
      "Epoch 90/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1006 - accuracy: 0.9679 - val_loss: 0.0471 - val_accuracy: 0.9810\n",
      "Epoch 91/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1018 - accuracy: 0.9691 - val_loss: 0.0478 - val_accuracy: 0.9810\n",
      "Epoch 92/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1030 - accuracy: 0.9680 - val_loss: 0.0445 - val_accuracy: 0.9833\n",
      "Epoch 93/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1020 - accuracy: 0.9686 - val_loss: 0.0463 - val_accuracy: 0.9833\n",
      "Epoch 94/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1014 - accuracy: 0.9686 - val_loss: 0.0440 - val_accuracy: 0.9833\n",
      "Epoch 95/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1019 - accuracy: 0.9687 - val_loss: 0.0478 - val_accuracy: 0.9833\n",
      "Epoch 96/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.0971 - accuracy: 0.9693 - val_loss: 0.0485 - val_accuracy: 0.9833\n",
      "Epoch 97/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1016 - accuracy: 0.9695 - val_loss: 0.0464 - val_accuracy: 0.9833\n",
      "Epoch 98/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1003 - accuracy: 0.9687 - val_loss: 0.0449 - val_accuracy: 0.9810\n",
      "Epoch 99/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1012 - accuracy: 0.9690 - val_loss: 0.0452 - val_accuracy: 0.9833\n",
      "Epoch 100/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1002 - accuracy: 0.9696 - val_loss: 0.0451 - val_accuracy: 0.9810\n",
      "model_1 재학습 1번 완료\n",
      "Epoch 1/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1060 - accuracy: 0.9672 - val_loss: 0.0446 - val_accuracy: 0.9810\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1072 - accuracy: 0.9672 - val_loss: 0.0439 - val_accuracy: 0.9833\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1052 - accuracy: 0.9673 - val_loss: 0.0436 - val_accuracy: 0.9810\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1035 - accuracy: 0.9675 - val_loss: 0.0449 - val_accuracy: 0.9833\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1051 - accuracy: 0.9683 - val_loss: 0.0413 - val_accuracy: 0.9833\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1035 - accuracy: 0.9678 - val_loss: 0.0393 - val_accuracy: 0.9833\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1029 - accuracy: 0.9684 - val_loss: 0.0335 - val_accuracy: 0.9881\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1041 - accuracy: 0.9681 - val_loss: 0.0348 - val_accuracy: 0.9857\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1017 - accuracy: 0.9687 - val_loss: 0.0356 - val_accuracy: 0.9857\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1008 - accuracy: 0.9685 - val_loss: 0.0381 - val_accuracy: 0.9833\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1025 - accuracy: 0.9688 - val_loss: 0.0360 - val_accuracy: 0.9833\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.0984 - accuracy: 0.9702 - val_loss: 0.0352 - val_accuracy: 0.9881\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1004 - accuracy: 0.9696 - val_loss: 0.0345 - val_accuracy: 0.9833\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.0992 - accuracy: 0.9698 - val_loss: 0.0289 - val_accuracy: 0.9905\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1003 - accuracy: 0.9693 - val_loss: 0.0282 - val_accuracy: 0.9881\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1011 - accuracy: 0.9696 - val_loss: 0.0305 - val_accuracy: 0.9881\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1018 - accuracy: 0.9693 - val_loss: 0.0277 - val_accuracy: 0.9881\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.0999 - accuracy: 0.9691 - val_loss: 0.0308 - val_accuracy: 0.9881\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.0992 - accuracy: 0.9694 - val_loss: 0.0283 - val_accuracy: 0.9881\n",
      "Epoch 20/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.0990 - accuracy: 0.9699 - val_loss: 0.0294 - val_accuracy: 0.9881\n",
      "Epoch 21/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1000 - accuracy: 0.9684 - val_loss: 0.0298 - val_accuracy: 0.9881\n",
      "Epoch 22/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.0974 - accuracy: 0.9699 - val_loss: 0.0278 - val_accuracy: 0.9929\n",
      "Epoch 23/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.0969 - accuracy: 0.9699 - val_loss: 0.0284 - val_accuracy: 0.9881\n",
      "Epoch 24/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.0976 - accuracy: 0.9702 - val_loss: 0.0296 - val_accuracy: 0.9905\n",
      "Epoch 25/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.0993 - accuracy: 0.9693 - val_loss: 0.0291 - val_accuracy: 0.9905\n",
      "Epoch 26/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.0970 - accuracy: 0.9697 - val_loss: 0.0290 - val_accuracy: 0.9905\n",
      "Epoch 27/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.0980 - accuracy: 0.9695 - val_loss: 0.0272 - val_accuracy: 0.9905\n",
      "Epoch 28/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.0955 - accuracy: 0.9703 - val_loss: 0.0272 - val_accuracy: 0.9905\n",
      "Epoch 29/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.0972 - accuracy: 0.9698 - val_loss: 0.0267 - val_accuracy: 0.9905\n",
      "Epoch 30/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.0967 - accuracy: 0.9704 - val_loss: 0.0275 - val_accuracy: 0.9881\n",
      "Epoch 31/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.0956 - accuracy: 0.9703 - val_loss: 0.0292 - val_accuracy: 0.9905\n",
      "Epoch 32/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.0965 - accuracy: 0.9704 - val_loss: 0.0251 - val_accuracy: 0.9905\n",
      "Epoch 33/100\n",
      "704/704 [==============================] - 20s 29ms/step - loss: 0.1004 - accuracy: 0.9702 - val_loss: 0.0248 - val_accuracy: 0.9905\n",
      "Epoch 34/100\n",
      "704/704 [==============================] - 19s 27ms/step - loss: 0.0962 - accuracy: 0.9704 - val_loss: 0.0279 - val_accuracy: 0.9905\n",
      "Epoch 35/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.0951 - accuracy: 0.9708 - val_loss: 0.0253 - val_accuracy: 0.9905\n",
      "Epoch 36/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.0938 - accuracy: 0.9711 - val_loss: 0.0262 - val_accuracy: 0.9905\n",
      "Epoch 37/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.0936 - accuracy: 0.9705 - val_loss: 0.0281 - val_accuracy: 0.9929\n",
      "Epoch 38/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.0953 - accuracy: 0.9707 - val_loss: 0.0271 - val_accuracy: 0.9929\n",
      "Epoch 39/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.0946 - accuracy: 0.9712 - val_loss: 0.0255 - val_accuracy: 0.9905\n",
      "Epoch 40/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.0961 - accuracy: 0.9706 - val_loss: 0.0263 - val_accuracy: 0.9905\n",
      "Epoch 41/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.0960 - accuracy: 0.9709 - val_loss: 0.0273 - val_accuracy: 0.9905\n",
      "Epoch 42/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.0909 - accuracy: 0.9720 - val_loss: 0.0288 - val_accuracy: 0.9905\n",
      "Epoch 43/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.0959 - accuracy: 0.9707 - val_loss: 0.0271 - val_accuracy: 0.9881\n",
      "Epoch 44/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.0943 - accuracy: 0.9714 - val_loss: 0.0243 - val_accuracy: 0.9929\n",
      "Epoch 45/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.0958 - accuracy: 0.9707 - val_loss: 0.0262 - val_accuracy: 0.9929\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 17s 24ms/step - loss: 0.0921 - accuracy: 0.9712 - val_loss: 0.0261 - val_accuracy: 0.9905\n",
      "Epoch 47/100\n",
      "704/704 [==============================] - 19s 27ms/step - loss: 0.0931 - accuracy: 0.9718 - val_loss: 0.0274 - val_accuracy: 0.9905\n",
      "Epoch 48/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.0912 - accuracy: 0.9717 - val_loss: 0.0266 - val_accuracy: 0.9905\n",
      "Epoch 49/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.0905 - accuracy: 0.9715 - val_loss: 0.0278 - val_accuracy: 0.9929\n",
      "Epoch 50/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.0936 - accuracy: 0.9709 - val_loss: 0.0257 - val_accuracy: 0.9905\n",
      "Epoch 51/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.0942 - accuracy: 0.9711 - val_loss: 0.0243 - val_accuracy: 0.9905\n",
      "Epoch 52/100\n",
      "704/704 [==============================] - 17s 25ms/step - loss: 0.0922 - accuracy: 0.9717 - val_loss: 0.0237 - val_accuracy: 0.9929\n",
      "Epoch 53/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.0933 - accuracy: 0.9717 - val_loss: 0.0210 - val_accuracy: 0.9952\n",
      "Epoch 54/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.0950 - accuracy: 0.9703 - val_loss: 0.0239 - val_accuracy: 0.9929\n",
      "Epoch 55/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.0914 - accuracy: 0.9723 - val_loss: 0.0225 - val_accuracy: 0.9929\n",
      "Epoch 56/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.0926 - accuracy: 0.9709 - val_loss: 0.0215 - val_accuracy: 0.9929\n",
      "Epoch 57/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.0946 - accuracy: 0.9713 - val_loss: 0.0212 - val_accuracy: 0.9952\n",
      "Epoch 58/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.0911 - accuracy: 0.9716 - val_loss: 0.0238 - val_accuracy: 0.9929\n",
      "Epoch 59/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.0914 - accuracy: 0.9716 - val_loss: 0.0223 - val_accuracy: 0.9929\n",
      "Epoch 60/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.0902 - accuracy: 0.9720 - val_loss: 0.0217 - val_accuracy: 0.9929\n",
      "Epoch 61/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.0902 - accuracy: 0.9724 - val_loss: 0.0206 - val_accuracy: 0.9929\n",
      "Epoch 62/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.0899 - accuracy: 0.9718 - val_loss: 0.0197 - val_accuracy: 0.9929\n",
      "Epoch 63/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.0886 - accuracy: 0.9730 - val_loss: 0.0192 - val_accuracy: 0.9952\n",
      "Epoch 64/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.0914 - accuracy: 0.9720 - val_loss: 0.0206 - val_accuracy: 0.9929\n",
      "Epoch 65/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.0890 - accuracy: 0.9729 - val_loss: 0.0220 - val_accuracy: 0.9929\n",
      "Epoch 66/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.0890 - accuracy: 0.9728 - val_loss: 0.0217 - val_accuracy: 0.9929\n",
      "Epoch 67/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.0911 - accuracy: 0.9716 - val_loss: 0.0215 - val_accuracy: 0.9929\n",
      "Epoch 68/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.0923 - accuracy: 0.9721 - val_loss: 0.0209 - val_accuracy: 0.9952\n",
      "Epoch 69/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.0914 - accuracy: 0.9716 - val_loss: 0.0224 - val_accuracy: 0.9929\n",
      "Epoch 70/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.0841 - accuracy: 0.9739 - val_loss: 0.0201 - val_accuracy: 0.9952\n",
      "Epoch 71/100\n",
      "704/704 [==============================] - 17s 23ms/step - loss: 0.0934 - accuracy: 0.9722 - val_loss: 0.0209 - val_accuracy: 0.9929\n",
      "Epoch 72/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.0877 - accuracy: 0.9729 - val_loss: 0.0210 - val_accuracy: 0.9929\n",
      "Epoch 73/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.0912 - accuracy: 0.9725 - val_loss: 0.0197 - val_accuracy: 0.9952\n",
      "Epoch 74/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.0900 - accuracy: 0.9724 - val_loss: 0.0218 - val_accuracy: 0.9952\n",
      "Epoch 75/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.0883 - accuracy: 0.9730 - val_loss: 0.0209 - val_accuracy: 0.9905\n",
      "Epoch 76/100\n",
      "704/704 [==============================] - 18s 26ms/step - loss: 0.0890 - accuracy: 0.9724 - val_loss: 0.0220 - val_accuracy: 0.9905\n",
      "Epoch 77/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.0904 - accuracy: 0.9724 - val_loss: 0.0218 - val_accuracy: 0.9905\n",
      "Epoch 78/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.0876 - accuracy: 0.9729 - val_loss: 0.0222 - val_accuracy: 0.9905\n",
      "Epoch 79/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.0865 - accuracy: 0.9740 - val_loss: 0.0210 - val_accuracy: 0.9929\n",
      "Epoch 80/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.0863 - accuracy: 0.9733 - val_loss: 0.0194 - val_accuracy: 0.9929\n",
      "Epoch 81/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.0876 - accuracy: 0.9732 - val_loss: 0.0184 - val_accuracy: 0.9952\n",
      "Epoch 82/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.0851 - accuracy: 0.9744 - val_loss: 0.0176 - val_accuracy: 0.9952\n",
      "Epoch 83/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.0856 - accuracy: 0.9732 - val_loss: 0.0219 - val_accuracy: 0.9929\n",
      "Epoch 84/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.0880 - accuracy: 0.9732 - val_loss: 0.0188 - val_accuracy: 0.9952\n",
      "Epoch 85/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.0875 - accuracy: 0.9726 - val_loss: 0.0195 - val_accuracy: 0.9952\n",
      "Epoch 86/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.0862 - accuracy: 0.9732 - val_loss: 0.0210 - val_accuracy: 0.9929\n",
      "Epoch 87/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.0864 - accuracy: 0.9732 - val_loss: 0.0190 - val_accuracy: 0.9952\n",
      "Epoch 88/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.0895 - accuracy: 0.9715 - val_loss: 0.0210 - val_accuracy: 0.9929\n",
      "Epoch 89/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.0865 - accuracy: 0.9736 - val_loss: 0.0208 - val_accuracy: 0.9929\n",
      "Epoch 90/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.0877 - accuracy: 0.9734 - val_loss: 0.0192 - val_accuracy: 0.9952\n",
      "Epoch 91/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.0893 - accuracy: 0.9729 - val_loss: 0.0192 - val_accuracy: 0.9952\n",
      "Epoch 92/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.0867 - accuracy: 0.9731 - val_loss: 0.0195 - val_accuracy: 0.9952\n",
      "Epoch 93/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.0855 - accuracy: 0.9739 - val_loss: 0.0189 - val_accuracy: 0.9952\n",
      "Epoch 94/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.0895 - accuracy: 0.9730 - val_loss: 0.0182 - val_accuracy: 0.9952\n",
      "Epoch 95/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.0859 - accuracy: 0.9736 - val_loss: 0.0207 - val_accuracy: 0.9952\n",
      "Epoch 96/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.0862 - accuracy: 0.9732 - val_loss: 0.0183 - val_accuracy: 0.9952\n",
      "Epoch 97/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.0879 - accuracy: 0.9731 - val_loss: 0.0210 - val_accuracy: 0.9929\n",
      "Epoch 98/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.0859 - accuracy: 0.9741 - val_loss: 0.0184 - val_accuracy: 0.9952\n",
      "Epoch 99/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.0862 - accuracy: 0.9732 - val_loss: 0.0198 - val_accuracy: 0.9952\n",
      "Epoch 100/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.0853 - accuracy: 0.9737 - val_loss: 0.0195 - val_accuracy: 0.9952\n",
      "model_1 재학습 2번 완료\n",
      "model_1 저장\n",
      "\n",
      "Epoch 1/1000\n",
      "703/703 [==============================] - 17s 23ms/step - loss: 1.3305 - accuracy: 0.4039 - val_loss: 1.3504 - val_accuracy: 0.3833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 1.1858 - accuracy: 0.4848 - val_loss: 1.2424 - val_accuracy: 0.4643\n",
      "Epoch 3/1000\n",
      "703/703 [==============================] - 18s 25ms/step - loss: 1.1127 - accuracy: 0.5292 - val_loss: 1.1326 - val_accuracy: 0.5381\n",
      "Epoch 4/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 1.0358 - accuracy: 0.5747 - val_loss: 1.0224 - val_accuracy: 0.5810\n",
      "Epoch 5/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.9644 - accuracy: 0.6163 - val_loss: 0.9268 - val_accuracy: 0.6286\n",
      "Epoch 6/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.8948 - accuracy: 0.6516 - val_loss: 0.8406 - val_accuracy: 0.6857\n",
      "Epoch 7/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.8386 - accuracy: 0.6766 - val_loss: 0.7902 - val_accuracy: 0.7048\n",
      "Epoch 8/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.7882 - accuracy: 0.6997 - val_loss: 0.7724 - val_accuracy: 0.6929\n",
      "Epoch 9/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.7427 - accuracy: 0.7233 - val_loss: 0.7230 - val_accuracy: 0.7381\n",
      "Epoch 10/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.7034 - accuracy: 0.7385 - val_loss: 0.6418 - val_accuracy: 0.7429\n",
      "Epoch 11/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.6753 - accuracy: 0.7518 - val_loss: 0.6207 - val_accuracy: 0.7524\n",
      "Epoch 12/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.6442 - accuracy: 0.7656 - val_loss: 0.6114 - val_accuracy: 0.7786\n",
      "Epoch 13/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.6242 - accuracy: 0.7756 - val_loss: 0.5912 - val_accuracy: 0.7786\n",
      "Epoch 14/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.5979 - accuracy: 0.7856 - val_loss: 0.5979 - val_accuracy: 0.7786\n",
      "Epoch 15/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.5834 - accuracy: 0.7935 - val_loss: 0.5479 - val_accuracy: 0.7952\n",
      "Epoch 16/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.5598 - accuracy: 0.8021 - val_loss: 0.5726 - val_accuracy: 0.7952\n",
      "Epoch 17/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.5463 - accuracy: 0.8077 - val_loss: 0.5218 - val_accuracy: 0.8048\n",
      "Epoch 18/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.5263 - accuracy: 0.8157 - val_loss: 0.5328 - val_accuracy: 0.8167\n",
      "Epoch 19/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.5052 - accuracy: 0.8233 - val_loss: 0.5565 - val_accuracy: 0.7905\n",
      "Epoch 20/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4988 - accuracy: 0.8265 - val_loss: 0.5797 - val_accuracy: 0.8048\n",
      "Epoch 21/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.4856 - accuracy: 0.8316 - val_loss: 0.5126 - val_accuracy: 0.8238\n",
      "Epoch 22/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.4762 - accuracy: 0.8375 - val_loss: 0.5158 - val_accuracy: 0.8476\n",
      "Epoch 23/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.4576 - accuracy: 0.8420 - val_loss: 0.4905 - val_accuracy: 0.8595\n",
      "Epoch 24/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.4497 - accuracy: 0.8465 - val_loss: 0.4999 - val_accuracy: 0.8524\n",
      "Epoch 25/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4387 - accuracy: 0.8516 - val_loss: 0.5145 - val_accuracy: 0.8333\n",
      "Epoch 26/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4329 - accuracy: 0.8536 - val_loss: 0.5324 - val_accuracy: 0.8262\n",
      "Epoch 27/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.4233 - accuracy: 0.8549 - val_loss: 0.4947 - val_accuracy: 0.8429\n",
      "Epoch 28/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.4161 - accuracy: 0.8583 - val_loss: 0.4444 - val_accuracy: 0.8595\n",
      "Epoch 29/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.4066 - accuracy: 0.8618 - val_loss: 0.4814 - val_accuracy: 0.8595\n",
      "Epoch 30/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.4001 - accuracy: 0.8657 - val_loss: 0.4989 - val_accuracy: 0.8405\n",
      "Epoch 31/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.3908 - accuracy: 0.8678 - val_loss: 0.4397 - val_accuracy: 0.8595\n",
      "Epoch 32/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.3796 - accuracy: 0.8735 - val_loss: 0.4371 - val_accuracy: 0.8690\n",
      "Epoch 33/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.3742 - accuracy: 0.8749 - val_loss: 0.4048 - val_accuracy: 0.8619\n",
      "Epoch 34/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.3721 - accuracy: 0.8757 - val_loss: 0.4516 - val_accuracy: 0.8667\n",
      "Epoch 35/1000\n",
      "703/703 [==============================] - 18s 26ms/step - loss: 0.3624 - accuracy: 0.8784 - val_loss: 0.4500 - val_accuracy: 0.8548\n",
      "Epoch 36/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.3565 - accuracy: 0.8807 - val_loss: 0.4703 - val_accuracy: 0.8524\n",
      "Epoch 37/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.3554 - accuracy: 0.8818 - val_loss: 0.4282 - val_accuracy: 0.8690\n",
      "Epoch 38/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.3518 - accuracy: 0.8841 - val_loss: 0.4271 - val_accuracy: 0.8667\n",
      "Epoch 39/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.3413 - accuracy: 0.8855 - val_loss: 0.4055 - val_accuracy: 0.8595\n",
      "Epoch 40/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3439 - accuracy: 0.8856 - val_loss: 0.4386 - val_accuracy: 0.8667\n",
      "Epoch 41/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.3326 - accuracy: 0.8898 - val_loss: 0.4098 - val_accuracy: 0.8738\n",
      "Epoch 42/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.3295 - accuracy: 0.8909 - val_loss: 0.4425 - val_accuracy: 0.8643\n",
      "Epoch 43/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3282 - accuracy: 0.8925 - val_loss: 0.4342 - val_accuracy: 0.8714\n",
      "Epoch 44/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3200 - accuracy: 0.8946 - val_loss: 0.4642 - val_accuracy: 0.8667\n",
      "Epoch 45/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3179 - accuracy: 0.8947 - val_loss: 0.4097 - val_accuracy: 0.8833\n",
      "Epoch 46/1000\n",
      "703/703 [==============================] - 17s 25ms/step - loss: 0.3138 - accuracy: 0.8973 - val_loss: 0.4315 - val_accuracy: 0.8881\n",
      "Epoch 47/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.3068 - accuracy: 0.9004 - val_loss: 0.4672 - val_accuracy: 0.8643\n",
      "Epoch 48/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.3079 - accuracy: 0.8992 - val_loss: 0.4427 - val_accuracy: 0.8786\n",
      "Epoch 49/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.3054 - accuracy: 0.8999 - val_loss: 0.4068 - val_accuracy: 0.8833\n",
      "Epoch 50/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.3001 - accuracy: 0.9013 - val_loss: 0.4682 - val_accuracy: 0.8690\n",
      "Epoch 51/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.2947 - accuracy: 0.9037 - val_loss: 0.5191 - val_accuracy: 0.8690\n",
      "Epoch 52/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.2956 - accuracy: 0.9046 - val_loss: 0.4222 - val_accuracy: 0.8905\n",
      "Epoch 53/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.2949 - accuracy: 0.9034 - val_loss: 0.4112 - val_accuracy: 0.8881\n",
      "Epoch 54/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.2877 - accuracy: 0.9072 - val_loss: 0.4552 - val_accuracy: 0.8714\n",
      "Epoch 55/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2854 - accuracy: 0.9076 - val_loss: 0.4177 - val_accuracy: 0.8714\n",
      "Epoch 56/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.2846 - accuracy: 0.9075 - val_loss: 0.4625 - val_accuracy: 0.8833\n",
      "Epoch 57/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.2790 - accuracy: 0.9089 - val_loss: 0.4426 - val_accuracy: 0.8905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2791 - accuracy: 0.9096 - val_loss: 0.4778 - val_accuracy: 0.8738\n",
      "Epoch 59/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.2779 - accuracy: 0.9094 - val_loss: 0.4394 - val_accuracy: 0.8786\n",
      "Epoch 60/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2726 - accuracy: 0.9118 - val_loss: 0.4135 - val_accuracy: 0.8857\n",
      "Epoch 61/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.2741 - accuracy: 0.9115 - val_loss: 0.4501 - val_accuracy: 0.8810\n",
      "Epoch 62/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.2705 - accuracy: 0.9128 - val_loss: 0.4289 - val_accuracy: 0.8905\n",
      "Epoch 63/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2654 - accuracy: 0.9148 - val_loss: 0.4227 - val_accuracy: 0.8881\n",
      "Epoch 64/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.2608 - accuracy: 0.9163 - val_loss: 0.4385 - val_accuracy: 0.8833\n",
      "Epoch 65/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.2642 - accuracy: 0.9158 - val_loss: 0.4346 - val_accuracy: 0.8762\n",
      "Epoch 66/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.2630 - accuracy: 0.9155 - val_loss: 0.4242 - val_accuracy: 0.8905\n",
      "Epoch 67/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.2576 - accuracy: 0.9174 - val_loss: 0.4438 - val_accuracy: 0.8738\n",
      "Epoch 68/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.2523 - accuracy: 0.9183 - val_loss: 0.4407 - val_accuracy: 0.8833\n",
      "Epoch 69/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.2521 - accuracy: 0.9192 - val_loss: 0.3955 - val_accuracy: 0.8905\n",
      "Epoch 70/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.2471 - accuracy: 0.9208 - val_loss: 0.4578 - val_accuracy: 0.8857\n",
      "Epoch 71/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.2571 - accuracy: 0.9175 - val_loss: 0.3877 - val_accuracy: 0.8929\n",
      "Epoch 72/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.2449 - accuracy: 0.9212 - val_loss: 0.4172 - val_accuracy: 0.8952\n",
      "Epoch 73/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2513 - accuracy: 0.9209 - val_loss: 0.4391 - val_accuracy: 0.8857\n",
      "Epoch 74/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.2440 - accuracy: 0.9220 - val_loss: 0.4250 - val_accuracy: 0.8905\n",
      "Epoch 75/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2443 - accuracy: 0.9218 - val_loss: 0.4215 - val_accuracy: 0.8929\n",
      "Epoch 76/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2465 - accuracy: 0.9216 - val_loss: 0.4714 - val_accuracy: 0.8786\n",
      "Epoch 77/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2375 - accuracy: 0.9236 - val_loss: 0.3887 - val_accuracy: 0.9024\n",
      "Epoch 78/1000\n",
      "703/703 [==============================] - 18s 25ms/step - loss: 0.2384 - accuracy: 0.9230 - val_loss: 0.4521 - val_accuracy: 0.8762\n",
      "Epoch 79/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.2384 - accuracy: 0.9254 - val_loss: 0.4308 - val_accuracy: 0.8929\n",
      "Epoch 80/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2348 - accuracy: 0.9255 - val_loss: 0.4081 - val_accuracy: 0.8929\n",
      "Epoch 81/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.2354 - accuracy: 0.9247 - val_loss: 0.4396 - val_accuracy: 0.8857\n",
      "Epoch 82/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2299 - accuracy: 0.9262 - val_loss: 0.4347 - val_accuracy: 0.8905\n",
      "Epoch 83/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2295 - accuracy: 0.9277 - val_loss: 0.4287 - val_accuracy: 0.8976\n",
      "Epoch 84/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.2308 - accuracy: 0.9261 - val_loss: 0.4413 - val_accuracy: 0.8905\n",
      "Epoch 85/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.2282 - accuracy: 0.9283 - val_loss: 0.4417 - val_accuracy: 0.9000\n",
      "Epoch 86/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2272 - accuracy: 0.9281 - val_loss: 0.4662 - val_accuracy: 0.8952\n",
      "Epoch 87/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2216 - accuracy: 0.9301 - val_loss: 0.4498 - val_accuracy: 0.8810\n",
      "Epoch 88/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2261 - accuracy: 0.9284 - val_loss: 0.4085 - val_accuracy: 0.8952\n",
      "Epoch 89/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.2233 - accuracy: 0.9293 - val_loss: 0.4369 - val_accuracy: 0.9024\n",
      "Epoch 90/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.2223 - accuracy: 0.9308 - val_loss: 0.4155 - val_accuracy: 0.8905\n",
      "Epoch 91/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2229 - accuracy: 0.9299 - val_loss: 0.4285 - val_accuracy: 0.8929\n",
      "Epoch 92/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2221 - accuracy: 0.9295 - val_loss: 0.4485 - val_accuracy: 0.8810\n",
      "Epoch 93/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2197 - accuracy: 0.9315 - val_loss: 0.4443 - val_accuracy: 0.8929\n",
      "Epoch 94/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.2193 - accuracy: 0.9310 - val_loss: 0.3617 - val_accuracy: 0.8929\n",
      "Epoch 95/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.2223 - accuracy: 0.9317 - val_loss: 0.3833 - val_accuracy: 0.9000\n",
      "Epoch 96/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.2133 - accuracy: 0.9331 - val_loss: 0.3878 - val_accuracy: 0.9000\n",
      "Epoch 97/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2169 - accuracy: 0.9321 - val_loss: 0.4241 - val_accuracy: 0.8905\n",
      "Epoch 98/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1896 - accuracy: 0.9400 - val_loss: 0.4222 - val_accuracy: 0.8952\n",
      "Epoch 99/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1848 - accuracy: 0.9417 - val_loss: 0.4455 - val_accuracy: 0.8857\n",
      "Epoch 100/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1799 - accuracy: 0.9427 - val_loss: 0.4490 - val_accuracy: 0.8857\n",
      "Epoch 101/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1766 - accuracy: 0.9455 - val_loss: 0.4888 - val_accuracy: 0.8929\n",
      "Epoch 102/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1752 - accuracy: 0.9441 - val_loss: 0.4490 - val_accuracy: 0.8857\n",
      "Epoch 103/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1746 - accuracy: 0.9452 - val_loss: 0.4856 - val_accuracy: 0.8881\n",
      "Epoch 104/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1749 - accuracy: 0.9459 - val_loss: 0.4388 - val_accuracy: 0.9000\n",
      "Epoch 105/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1715 - accuracy: 0.9459 - val_loss: 0.4828 - val_accuracy: 0.8952\n",
      "Epoch 106/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1662 - accuracy: 0.9477 - val_loss: 0.5008 - val_accuracy: 0.8905\n",
      "Epoch 107/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1678 - accuracy: 0.9475 - val_loss: 0.4883 - val_accuracy: 0.8929\n",
      "Epoch 108/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1700 - accuracy: 0.9474 - val_loss: 0.4498 - val_accuracy: 0.9024\n",
      "Epoch 109/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.1661 - accuracy: 0.9481 - val_loss: 0.4482 - val_accuracy: 0.8929\n",
      "Epoch 110/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1656 - accuracy: 0.9480 - val_loss: 0.4086 - val_accuracy: 0.9000\n",
      "Epoch 111/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1667 - accuracy: 0.9484 - val_loss: 0.4583 - val_accuracy: 0.9000\n",
      "Epoch 112/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1640 - accuracy: 0.9490 - val_loss: 0.4559 - val_accuracy: 0.9000\n",
      "Epoch 113/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1603 - accuracy: 0.9490 - val_loss: 0.4266 - val_accuracy: 0.8929\n",
      "Epoch 114/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1613 - accuracy: 0.9496 - val_loss: 0.4588 - val_accuracy: 0.8976\n",
      "Epoch 115/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1638 - accuracy: 0.9485 - val_loss: 0.4584 - val_accuracy: 0.8881\n",
      "Epoch 116/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1625 - accuracy: 0.9488 - val_loss: 0.4748 - val_accuracy: 0.9000\n",
      "Epoch 117/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1520 - accuracy: 0.9524 - val_loss: 0.4620 - val_accuracy: 0.8976\n",
      "Epoch 118/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1501 - accuracy: 0.9534 - val_loss: 0.4756 - val_accuracy: 0.9071\n",
      "Epoch 119/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.1460 - accuracy: 0.9548 - val_loss: 0.4447 - val_accuracy: 0.8952\n",
      "Epoch 120/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1429 - accuracy: 0.9547 - val_loss: 0.4802 - val_accuracy: 0.8976\n",
      "Epoch 121/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.1456 - accuracy: 0.9552 - val_loss: 0.4302 - val_accuracy: 0.9024\n",
      "Epoch 122/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1397 - accuracy: 0.9563 - val_loss: 0.4584 - val_accuracy: 0.9024\n",
      "Epoch 123/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.1386 - accuracy: 0.9560 - val_loss: 0.4442 - val_accuracy: 0.9024\n",
      "Epoch 124/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1393 - accuracy: 0.9571 - val_loss: 0.4397 - val_accuracy: 0.8952\n",
      "Epoch 125/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.1374 - accuracy: 0.9570 - val_loss: 0.4604 - val_accuracy: 0.9024\n",
      "Epoch 126/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.1335 - accuracy: 0.9577 - val_loss: 0.4712 - val_accuracy: 0.9024\n",
      "Epoch 127/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1359 - accuracy: 0.9570 - val_loss: 0.4681 - val_accuracy: 0.9048\n",
      "Epoch 128/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1356 - accuracy: 0.9567 - val_loss: 0.4687 - val_accuracy: 0.9000\n",
      "Epoch 129/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1355 - accuracy: 0.9571 - val_loss: 0.4405 - val_accuracy: 0.9071\n",
      "Epoch 130/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1368 - accuracy: 0.9570 - val_loss: 0.4292 - val_accuracy: 0.9000\n",
      "Epoch 131/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1334 - accuracy: 0.9585 - val_loss: 0.4187 - val_accuracy: 0.9000\n",
      "Epoch 132/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1348 - accuracy: 0.9585 - val_loss: 0.4827 - val_accuracy: 0.8952\n",
      "Epoch 133/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1298 - accuracy: 0.9592 - val_loss: 0.4428 - val_accuracy: 0.9048\n",
      "Epoch 134/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1293 - accuracy: 0.9596 - val_loss: 0.4604 - val_accuracy: 0.9048\n",
      "Epoch 135/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1340 - accuracy: 0.9585 - val_loss: 0.4282 - val_accuracy: 0.9048\n",
      "Epoch 136/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1309 - accuracy: 0.9593 - val_loss: 0.4395 - val_accuracy: 0.8952\n",
      "Epoch 137/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1329 - accuracy: 0.9590 - val_loss: 0.4495 - val_accuracy: 0.9071\n",
      "Epoch 138/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1328 - accuracy: 0.9587 - val_loss: 0.4288 - val_accuracy: 0.9071\n",
      "Epoch 139/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1272 - accuracy: 0.9600 - val_loss: 0.4319 - val_accuracy: 0.9119\n",
      "Epoch 140/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1235 - accuracy: 0.9614 - val_loss: 0.4547 - val_accuracy: 0.9024\n",
      "Epoch 141/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1243 - accuracy: 0.9616 - val_loss: 0.4510 - val_accuracy: 0.9071\n",
      "Epoch 142/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1197 - accuracy: 0.9622 - val_loss: 0.4555 - val_accuracy: 0.9071\n",
      "Epoch 143/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1221 - accuracy: 0.9622 - val_loss: 0.4318 - val_accuracy: 0.9071\n",
      "Epoch 144/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1222 - accuracy: 0.9618 - val_loss: 0.4595 - val_accuracy: 0.9048\n",
      "Epoch 145/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1194 - accuracy: 0.9629 - val_loss: 0.4622 - val_accuracy: 0.9071\n",
      "Epoch 146/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1217 - accuracy: 0.9620 - val_loss: 0.4545 - val_accuracy: 0.9071\n",
      "Epoch 147/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.1191 - accuracy: 0.9627 - val_loss: 0.4757 - val_accuracy: 0.9048\n",
      "Epoch 148/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1228 - accuracy: 0.9618 - val_loss: 0.4373 - val_accuracy: 0.9095\n",
      "Epoch 149/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1216 - accuracy: 0.9623 - val_loss: 0.4729 - val_accuracy: 0.9119\n",
      "Epoch 150/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1222 - accuracy: 0.9612 - val_loss: 0.4845 - val_accuracy: 0.8976\n",
      "Epoch 151/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1200 - accuracy: 0.9621 - val_loss: 0.4897 - val_accuracy: 0.8976\n",
      "Epoch 152/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1189 - accuracy: 0.9630 - val_loss: 0.4745 - val_accuracy: 0.9048\n",
      "Epoch 153/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.1196 - accuracy: 0.9628 - val_loss: 0.4723 - val_accuracy: 0.9024\n",
      "Epoch 154/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1166 - accuracy: 0.9644 - val_loss: 0.4687 - val_accuracy: 0.9071\n",
      "Epoch 155/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1197 - accuracy: 0.9632 - val_loss: 0.4510 - val_accuracy: 0.9071\n",
      "Epoch 156/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1185 - accuracy: 0.9626 - val_loss: 0.4554 - val_accuracy: 0.9071\n",
      "Epoch 157/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1159 - accuracy: 0.9639 - val_loss: 0.4920 - val_accuracy: 0.9048\n",
      "Epoch 158/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1177 - accuracy: 0.9634 - val_loss: 0.4716 - val_accuracy: 0.9048\n",
      "Epoch 159/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1171 - accuracy: 0.9636 - val_loss: 0.4733 - val_accuracy: 0.9024\n",
      "Epoch 160/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1156 - accuracy: 0.9638 - val_loss: 0.4565 - val_accuracy: 0.9095\n",
      "Epoch 161/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1135 - accuracy: 0.9651 - val_loss: 0.4938 - val_accuracy: 0.9024\n",
      "Epoch 162/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1143 - accuracy: 0.9643 - val_loss: 0.4841 - val_accuracy: 0.9071\n",
      "Epoch 163/1000\n",
      "703/703 [==============================] - 18s 25ms/step - loss: 0.1128 - accuracy: 0.9646 - val_loss: 0.4670 - val_accuracy: 0.9095\n",
      "Epoch 164/1000\n",
      "703/703 [==============================] - 20s 28ms/step - loss: 0.1140 - accuracy: 0.9642 - val_loss: 0.4750 - val_accuracy: 0.9071\n",
      "Epoch 165/1000\n",
      "703/703 [==============================] - 17s 25ms/step - loss: 0.1149 - accuracy: 0.9645 - val_loss: 0.4651 - val_accuracy: 0.9071\n",
      "Epoch 166/1000\n",
      "703/703 [==============================] - 18s 25ms/step - loss: 0.1123 - accuracy: 0.9648 - val_loss: 0.4771 - val_accuracy: 0.9071\n",
      "Epoch 167/1000\n",
      "703/703 [==============================] - 18s 26ms/step - loss: 0.1134 - accuracy: 0.9651 - val_loss: 0.4605 - val_accuracy: 0.9071\n",
      "Epoch 168/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 18s 26ms/step - loss: 0.1140 - accuracy: 0.9649 - val_loss: 0.4726 - val_accuracy: 0.9024\n",
      "Epoch 169/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1151 - accuracy: 0.9643 - val_loss: 0.4608 - val_accuracy: 0.9000\n",
      "Epoch 170/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1156 - accuracy: 0.9642 - val_loss: 0.4680 - val_accuracy: 0.9048\n",
      "Epoch 171/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1136 - accuracy: 0.9644 - val_loss: 0.4836 - val_accuracy: 0.9048\n",
      "Epoch 172/1000\n",
      "703/703 [==============================] - 17s 25ms/step - loss: 0.1103 - accuracy: 0.9653 - val_loss: 0.5119 - val_accuracy: 0.8976\n",
      "Epoch 173/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1134 - accuracy: 0.9651 - val_loss: 0.4956 - val_accuracy: 0.9024\n",
      "Epoch 174/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1117 - accuracy: 0.9648 - val_loss: 0.4785 - val_accuracy: 0.9048\n",
      "Epoch 175/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1095 - accuracy: 0.9655 - val_loss: 0.4650 - val_accuracy: 0.9000\n",
      "Epoch 176/1000\n",
      "703/703 [==============================] - 19s 27ms/step - loss: 0.1083 - accuracy: 0.9662 - val_loss: 0.4670 - val_accuracy: 0.9095\n",
      "Epoch 177/1000\n",
      "703/703 [==============================] - 18s 26ms/step - loss: 0.1106 - accuracy: 0.9652 - val_loss: 0.4745 - val_accuracy: 0.9071\n",
      "Epoch 178/1000\n",
      "703/703 [==============================] - 17s 25ms/step - loss: 0.1089 - accuracy: 0.9657 - val_loss: 0.4909 - val_accuracy: 0.9024\n",
      "Epoch 179/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1129 - accuracy: 0.9647 - val_loss: 0.4753 - val_accuracy: 0.9000\n",
      "Epoch 180/1000\n",
      "703/703 [==============================] - 18s 25ms/step - loss: 0.1092 - accuracy: 0.9666 - val_loss: 0.4775 - val_accuracy: 0.9048\n",
      "Epoch 181/1000\n",
      "703/703 [==============================] - 18s 25ms/step - loss: 0.1108 - accuracy: 0.9660 - val_loss: 0.4759 - val_accuracy: 0.9048\n",
      "Epoch 182/1000\n",
      "703/703 [==============================] - 17s 25ms/step - loss: 0.1113 - accuracy: 0.9655 - val_loss: 0.4718 - val_accuracy: 0.9071\n",
      "Epoch 183/1000\n",
      "703/703 [==============================] - 18s 25ms/step - loss: 0.1094 - accuracy: 0.9656 - val_loss: 0.4661 - val_accuracy: 0.9071\n",
      "Epoch 184/1000\n",
      "703/703 [==============================] - 18s 25ms/step - loss: 0.1099 - accuracy: 0.9660 - val_loss: 0.4669 - val_accuracy: 0.9048\n",
      "Epoch 185/1000\n",
      "703/703 [==============================] - 18s 26ms/step - loss: 0.1097 - accuracy: 0.9657 - val_loss: 0.4717 - val_accuracy: 0.9071\n",
      "Epoch 186/1000\n",
      "703/703 [==============================] - 17s 25ms/step - loss: 0.1062 - accuracy: 0.9666 - val_loss: 0.4648 - val_accuracy: 0.9071\n",
      "Epoch 187/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1103 - accuracy: 0.9654 - val_loss: 0.4775 - val_accuracy: 0.9095\n",
      "Epoch 188/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1111 - accuracy: 0.9653 - val_loss: 0.4742 - val_accuracy: 0.9095\n",
      "Epoch 189/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1111 - accuracy: 0.9658 - val_loss: 0.4697 - val_accuracy: 0.9048\n",
      "Epoch 190/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1078 - accuracy: 0.9665 - val_loss: 0.4719 - val_accuracy: 0.9071\n",
      "Epoch 191/1000\n",
      "703/703 [==============================] - 20s 28ms/step - loss: 0.1096 - accuracy: 0.9663 - val_loss: 0.4733 - val_accuracy: 0.9071\n",
      "Epoch 192/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1065 - accuracy: 0.9660 - val_loss: 0.4727 - val_accuracy: 0.9095\n",
      "Epoch 193/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1091 - accuracy: 0.9659 - val_loss: 0.4720 - val_accuracy: 0.9048\n",
      "Epoch 194/1000\n",
      "703/703 [==============================] - 19s 27ms/step - loss: 0.1111 - accuracy: 0.9660 - val_loss: 0.4519 - val_accuracy: 0.9071\n",
      "Epoch 195/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.1095 - accuracy: 0.9666 - val_loss: 0.4626 - val_accuracy: 0.9071\n",
      "Epoch 196/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1085 - accuracy: 0.9661 - val_loss: 0.4810 - val_accuracy: 0.9071\n",
      "Epoch 197/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1075 - accuracy: 0.9668 - val_loss: 0.4729 - val_accuracy: 0.9071\n",
      "Epoch 198/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1087 - accuracy: 0.9659 - val_loss: 0.4721 - val_accuracy: 0.9071\n",
      "Epoch 199/1000\n",
      "703/703 [==============================] - 24s 34ms/step - loss: 0.1104 - accuracy: 0.9653 - val_loss: 0.4718 - val_accuracy: 0.9071\n",
      "Epoch 200/1000\n",
      "703/703 [==============================] - 21s 30ms/step - loss: 0.1086 - accuracy: 0.9660 - val_loss: 0.4735 - val_accuracy: 0.9095\n",
      "Epoch 201/1000\n",
      "703/703 [==============================] - 23s 33ms/step - loss: 0.1078 - accuracy: 0.9671 - val_loss: 0.4725 - val_accuracy: 0.9095\n",
      "Epoch 202/1000\n",
      "703/703 [==============================] - 21s 29ms/step - loss: 0.1063 - accuracy: 0.9674 - val_loss: 0.4756 - val_accuracy: 0.9095\n",
      "Epoch 203/1000\n",
      "703/703 [==============================] - 21s 29ms/step - loss: 0.1065 - accuracy: 0.9669 - val_loss: 0.4729 - val_accuracy: 0.9071\n",
      "Epoch 204/1000\n",
      "703/703 [==============================] - 28s 39ms/step - loss: 0.1065 - accuracy: 0.9668 - val_loss: 0.4802 - val_accuracy: 0.9095\n",
      "Epoch 205/1000\n",
      "703/703 [==============================] - 23s 32ms/step - loss: 0.1061 - accuracy: 0.9672 - val_loss: 0.4846 - val_accuracy: 0.9095\n",
      "Epoch 206/1000\n",
      "703/703 [==============================] - 23s 33ms/step - loss: 0.1064 - accuracy: 0.9667 - val_loss: 0.4797 - val_accuracy: 0.9071\n",
      "Epoch 207/1000\n",
      "703/703 [==============================] - 24s 34ms/step - loss: 0.1062 - accuracy: 0.9665 - val_loss: 0.4834 - val_accuracy: 0.9095\n",
      "Epoch 208/1000\n",
      "703/703 [==============================] - 22s 31ms/step - loss: 0.1066 - accuracy: 0.9671 - val_loss: 0.4798 - val_accuracy: 0.9095\n",
      "Epoch 209/1000\n",
      "703/703 [==============================] - 22s 31ms/step - loss: 0.1075 - accuracy: 0.9667 - val_loss: 0.4716 - val_accuracy: 0.9071\n",
      "Epoch 210/1000\n",
      "703/703 [==============================] - 22s 31ms/step - loss: 0.1055 - accuracy: 0.9668 - val_loss: 0.4787 - val_accuracy: 0.9071\n",
      "Epoch 211/1000\n",
      "703/703 [==============================] - 21s 30ms/step - loss: 0.1062 - accuracy: 0.9669 - val_loss: 0.4745 - val_accuracy: 0.9071\n",
      "Epoch 212/1000\n",
      "703/703 [==============================] - 23s 33ms/step - loss: 0.1048 - accuracy: 0.9670 - val_loss: 0.4797 - val_accuracy: 0.9095\n",
      "Epoch 213/1000\n",
      "703/703 [==============================] - 21s 31ms/step - loss: 0.1082 - accuracy: 0.9667 - val_loss: 0.4745 - val_accuracy: 0.9048\n",
      "Epoch 214/1000\n",
      "703/703 [==============================] - 21s 30ms/step - loss: 0.1081 - accuracy: 0.9664 - val_loss: 0.4730 - val_accuracy: 0.9095\n",
      "Epoch 00214: early stopping\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4730 - accuracy: 0.9095\n",
      "model_2 loss : [0.4729612171649933, 0.9095237851142883]\n",
      "Epoch 1/100\n",
      "704/704 [==============================] - 20s 29ms/step - loss: 0.1336 - accuracy: 0.9601 - val_loss: 0.4369 - val_accuracy: 0.9095\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 18s 26ms/step - loss: 0.1323 - accuracy: 0.9599 - val_loss: 0.4188 - val_accuracy: 0.9071\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1329 - accuracy: 0.9597 - val_loss: 0.4025 - val_accuracy: 0.9119\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.1325 - accuracy: 0.9601 - val_loss: 0.3852 - val_accuracy: 0.9119\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 20s 28ms/step - loss: 0.1334 - accuracy: 0.9599 - val_loss: 0.3781 - val_accuracy: 0.9119\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 21s 30ms/step - loss: 0.1298 - accuracy: 0.9606 - val_loss: 0.3802 - val_accuracy: 0.9143\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 21s 30ms/step - loss: 0.1293 - accuracy: 0.9606 - val_loss: 0.3645 - val_accuracy: 0.9143\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1295 - accuracy: 0.9606 - val_loss: 0.3597 - val_accuracy: 0.9143\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1323 - accuracy: 0.9604 - val_loss: 0.3577 - val_accuracy: 0.9143\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1293 - accuracy: 0.9612 - val_loss: 0.3439 - val_accuracy: 0.9143\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1270 - accuracy: 0.9620 - val_loss: 0.3402 - val_accuracy: 0.9143\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 19s 27ms/step - loss: 0.1282 - accuracy: 0.9614 - val_loss: 0.3340 - val_accuracy: 0.9167\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.1309 - accuracy: 0.9607 - val_loss: 0.3303 - val_accuracy: 0.9143\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1284 - accuracy: 0.9608 - val_loss: 0.3223 - val_accuracy: 0.9167\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1266 - accuracy: 0.9618 - val_loss: 0.3223 - val_accuracy: 0.9167\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1289 - accuracy: 0.9608 - val_loss: 0.3151 - val_accuracy: 0.9167\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1297 - accuracy: 0.9609 - val_loss: 0.3125 - val_accuracy: 0.9167\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1282 - accuracy: 0.9610 - val_loss: 0.3077 - val_accuracy: 0.9167\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1238 - accuracy: 0.9620 - val_loss: 0.3024 - val_accuracy: 0.9167\n",
      "Epoch 20/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1258 - accuracy: 0.9609 - val_loss: 0.3019 - val_accuracy: 0.9167\n",
      "Epoch 21/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1278 - accuracy: 0.9613 - val_loss: 0.2962 - val_accuracy: 0.9167\n",
      "Epoch 22/100\n",
      "704/704 [==============================] - 17s 25ms/step - loss: 0.1250 - accuracy: 0.9622 - val_loss: 0.2940 - val_accuracy: 0.9190\n",
      "Epoch 23/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1267 - accuracy: 0.9610 - val_loss: 0.2912 - val_accuracy: 0.9190\n",
      "Epoch 24/100\n",
      "704/704 [==============================] - 19s 27ms/step - loss: 0.1270 - accuracy: 0.9615 - val_loss: 0.2905 - val_accuracy: 0.9167\n",
      "Epoch 25/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.1273 - accuracy: 0.9609 - val_loss: 0.2809 - val_accuracy: 0.9190\n",
      "Epoch 26/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1269 - accuracy: 0.9611 - val_loss: 0.2854 - val_accuracy: 0.9190\n",
      "Epoch 27/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1238 - accuracy: 0.9628 - val_loss: 0.2755 - val_accuracy: 0.9190\n",
      "Epoch 28/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1278 - accuracy: 0.9620 - val_loss: 0.2748 - val_accuracy: 0.9190\n",
      "Epoch 29/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1269 - accuracy: 0.9612 - val_loss: 0.2743 - val_accuracy: 0.9190\n",
      "Epoch 30/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1287 - accuracy: 0.9620 - val_loss: 0.2691 - val_accuracy: 0.9167\n",
      "Epoch 31/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1290 - accuracy: 0.9613 - val_loss: 0.2644 - val_accuracy: 0.9190\n",
      "Epoch 32/100\n",
      "704/704 [==============================] - 18s 26ms/step - loss: 0.1278 - accuracy: 0.9609 - val_loss: 0.2626 - val_accuracy: 0.9214\n",
      "Epoch 33/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1236 - accuracy: 0.9617 - val_loss: 0.2636 - val_accuracy: 0.9167\n",
      "Epoch 34/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1282 - accuracy: 0.9610 - val_loss: 0.2565 - val_accuracy: 0.9214\n",
      "Epoch 35/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1249 - accuracy: 0.9617 - val_loss: 0.2624 - val_accuracy: 0.9190\n",
      "Epoch 36/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1258 - accuracy: 0.9622 - val_loss: 0.2521 - val_accuracy: 0.9190\n",
      "Epoch 37/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1244 - accuracy: 0.9621 - val_loss: 0.2507 - val_accuracy: 0.9190\n",
      "Epoch 38/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1250 - accuracy: 0.9620 - val_loss: 0.2539 - val_accuracy: 0.9190\n",
      "Epoch 39/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1229 - accuracy: 0.9622 - val_loss: 0.2469 - val_accuracy: 0.9190\n",
      "Epoch 40/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1227 - accuracy: 0.9624 - val_loss: 0.2473 - val_accuracy: 0.9214\n",
      "Epoch 41/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1244 - accuracy: 0.9621 - val_loss: 0.2444 - val_accuracy: 0.9238\n",
      "Epoch 42/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1209 - accuracy: 0.9626 - val_loss: 0.2400 - val_accuracy: 0.9238\n",
      "Epoch 43/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1255 - accuracy: 0.9624 - val_loss: 0.2380 - val_accuracy: 0.9238\n",
      "Epoch 44/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1242 - accuracy: 0.9614 - val_loss: 0.2374 - val_accuracy: 0.9262\n",
      "Epoch 45/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1246 - accuracy: 0.9612 - val_loss: 0.2353 - val_accuracy: 0.9262\n",
      "Epoch 46/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1234 - accuracy: 0.9621 - val_loss: 0.2309 - val_accuracy: 0.9262\n",
      "Epoch 47/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1228 - accuracy: 0.9626 - val_loss: 0.2292 - val_accuracy: 0.9286\n",
      "Epoch 48/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1259 - accuracy: 0.9618 - val_loss: 0.2241 - val_accuracy: 0.9286\n",
      "Epoch 49/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1206 - accuracy: 0.9628 - val_loss: 0.2266 - val_accuracy: 0.9286\n",
      "Epoch 50/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1235 - accuracy: 0.9623 - val_loss: 0.2285 - val_accuracy: 0.9286\n",
      "Epoch 51/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1240 - accuracy: 0.9621 - val_loss: 0.2280 - val_accuracy: 0.9238\n",
      "Epoch 52/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1240 - accuracy: 0.9624 - val_loss: 0.2176 - val_accuracy: 0.9262\n",
      "Epoch 53/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1218 - accuracy: 0.9625 - val_loss: 0.2184 - val_accuracy: 0.9262\n",
      "Epoch 54/100\n",
      "704/704 [==============================] - 14s 21ms/step - loss: 0.1201 - accuracy: 0.9627 - val_loss: 0.2180 - val_accuracy: 0.9286\n",
      "Epoch 55/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1213 - accuracy: 0.9627 - val_loss: 0.2163 - val_accuracy: 0.9310\n",
      "Epoch 56/100\n",
      "704/704 [==============================] - 14s 21ms/step - loss: 0.1218 - accuracy: 0.9626 - val_loss: 0.2107 - val_accuracy: 0.9333\n",
      "Epoch 57/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1198 - accuracy: 0.9632 - val_loss: 0.2153 - val_accuracy: 0.9310\n",
      "Epoch 58/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1208 - accuracy: 0.9628 - val_loss: 0.2214 - val_accuracy: 0.9286\n",
      "Epoch 59/100\n",
      "704/704 [==============================] - 25s 35ms/step - loss: 0.1226 - accuracy: 0.9631 - val_loss: 0.2119 - val_accuracy: 0.9310\n",
      "Epoch 60/100\n",
      "704/704 [==============================] - 53s 75ms/step - loss: 0.1235 - accuracy: 0.9623 - val_loss: 0.2030 - val_accuracy: 0.9333\n",
      "Epoch 61/100\n",
      "704/704 [==============================] - 53s 75ms/step - loss: 0.1200 - accuracy: 0.9632 - val_loss: 0.2061 - val_accuracy: 0.9286\n",
      "Epoch 62/100\n",
      "704/704 [==============================] - 53s 75ms/step - loss: 0.1234 - accuracy: 0.9616 - val_loss: 0.2088 - val_accuracy: 0.9286\n",
      "Epoch 63/100\n",
      "704/704 [==============================] - 53s 75ms/step - loss: 0.1250 - accuracy: 0.9621 - val_loss: 0.2106 - val_accuracy: 0.9262\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 52s 75ms/step - loss: 0.1213 - accuracy: 0.9633 - val_loss: 0.1955 - val_accuracy: 0.9286\n",
      "Epoch 65/100\n",
      "704/704 [==============================] - 42s 59ms/step - loss: 0.1219 - accuracy: 0.9622 - val_loss: 0.1995 - val_accuracy: 0.9357\n",
      "Epoch 66/100\n",
      "704/704 [==============================] - 22s 31ms/step - loss: 0.1222 - accuracy: 0.9630 - val_loss: 0.1923 - val_accuracy: 0.9357\n",
      "Epoch 67/100\n",
      "704/704 [==============================] - 20s 28ms/step - loss: 0.1232 - accuracy: 0.9620 - val_loss: 0.1959 - val_accuracy: 0.9357\n",
      "Epoch 68/100\n",
      "704/704 [==============================] - 18s 26ms/step - loss: 0.1211 - accuracy: 0.9633 - val_loss: 0.1954 - val_accuracy: 0.9357\n",
      "Epoch 69/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1221 - accuracy: 0.9631 - val_loss: 0.1852 - val_accuracy: 0.9357\n",
      "Epoch 70/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1189 - accuracy: 0.9632 - val_loss: 0.1967 - val_accuracy: 0.9333\n",
      "Epoch 71/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1217 - accuracy: 0.9627 - val_loss: 0.1888 - val_accuracy: 0.9357\n",
      "Epoch 72/100\n",
      "704/704 [==============================] - 14s 21ms/step - loss: 0.1182 - accuracy: 0.9636 - val_loss: 0.1878 - val_accuracy: 0.9357\n",
      "Epoch 73/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1224 - accuracy: 0.9622 - val_loss: 0.1847 - val_accuracy: 0.9357\n",
      "Epoch 74/100\n",
      "704/704 [==============================] - 14s 21ms/step - loss: 0.1177 - accuracy: 0.9640 - val_loss: 0.1868 - val_accuracy: 0.9357\n",
      "Epoch 75/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1213 - accuracy: 0.9624 - val_loss: 0.1856 - val_accuracy: 0.9333\n",
      "Epoch 76/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1193 - accuracy: 0.9636 - val_loss: 0.1829 - val_accuracy: 0.9357\n",
      "Epoch 77/100\n",
      "704/704 [==============================] - 14s 21ms/step - loss: 0.1216 - accuracy: 0.9633 - val_loss: 0.1862 - val_accuracy: 0.9357\n",
      "Epoch 78/100\n",
      "704/704 [==============================] - 14s 21ms/step - loss: 0.1226 - accuracy: 0.9621 - val_loss: 0.1875 - val_accuracy: 0.9357\n",
      "Epoch 79/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1203 - accuracy: 0.9636 - val_loss: 0.1791 - val_accuracy: 0.9381\n",
      "Epoch 80/100\n",
      "704/704 [==============================] - 14s 21ms/step - loss: 0.1186 - accuracy: 0.9629 - val_loss: 0.1872 - val_accuracy: 0.9357\n",
      "Epoch 81/100\n",
      "704/704 [==============================] - 14s 21ms/step - loss: 0.1220 - accuracy: 0.9624 - val_loss: 0.1849 - val_accuracy: 0.9381\n",
      "Epoch 82/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1189 - accuracy: 0.9629 - val_loss: 0.1821 - val_accuracy: 0.9381\n",
      "Epoch 83/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1173 - accuracy: 0.9637 - val_loss: 0.1765 - val_accuracy: 0.9405\n",
      "Epoch 84/100\n",
      "704/704 [==============================] - 14s 21ms/step - loss: 0.1196 - accuracy: 0.9632 - val_loss: 0.1794 - val_accuracy: 0.9405\n",
      "Epoch 85/100\n",
      "704/704 [==============================] - 14s 21ms/step - loss: 0.1210 - accuracy: 0.9633 - val_loss: 0.1741 - val_accuracy: 0.9405\n",
      "Epoch 86/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1193 - accuracy: 0.9635 - val_loss: 0.1835 - val_accuracy: 0.9452\n",
      "Epoch 87/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1187 - accuracy: 0.9640 - val_loss: 0.1747 - val_accuracy: 0.9429\n",
      "Epoch 88/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1194 - accuracy: 0.9632 - val_loss: 0.1784 - val_accuracy: 0.9405\n",
      "Epoch 89/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1197 - accuracy: 0.9632 - val_loss: 0.1722 - val_accuracy: 0.9429\n",
      "Epoch 90/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.1189 - accuracy: 0.9634 - val_loss: 0.1728 - val_accuracy: 0.9452\n",
      "Epoch 91/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1190 - accuracy: 0.9636 - val_loss: 0.1699 - val_accuracy: 0.9452\n",
      "Epoch 92/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1223 - accuracy: 0.9629 - val_loss: 0.1701 - val_accuracy: 0.9452\n",
      "Epoch 93/100\n",
      "704/704 [==============================] - 14s 21ms/step - loss: 0.1221 - accuracy: 0.9630 - val_loss: 0.1747 - val_accuracy: 0.9452\n",
      "Epoch 94/100\n",
      "704/704 [==============================] - 14s 21ms/step - loss: 0.1188 - accuracy: 0.9631 - val_loss: 0.1656 - val_accuracy: 0.9429\n",
      "Epoch 95/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1207 - accuracy: 0.9636 - val_loss: 0.1619 - val_accuracy: 0.9429\n",
      "Epoch 96/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1191 - accuracy: 0.9632 - val_loss: 0.1646 - val_accuracy: 0.9452\n",
      "Epoch 97/100\n",
      "704/704 [==============================] - 14s 21ms/step - loss: 0.1182 - accuracy: 0.9640 - val_loss: 0.1600 - val_accuracy: 0.9452\n",
      "Epoch 98/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1175 - accuracy: 0.9637 - val_loss: 0.1681 - val_accuracy: 0.9452\n",
      "Epoch 99/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1175 - accuracy: 0.9639 - val_loss: 0.1617 - val_accuracy: 0.9429\n",
      "Epoch 100/100\n",
      "704/704 [==============================] - 24s 35ms/step - loss: 0.1199 - accuracy: 0.9634 - val_loss: 0.1566 - val_accuracy: 0.9476\n",
      "model_2 재학습 1번 완료\n",
      "Epoch 1/100\n",
      "704/704 [==============================] - 23s 33ms/step - loss: 0.1227 - accuracy: 0.9627 - val_loss: 0.1553 - val_accuracy: 0.9429\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 23s 32ms/step - loss: 0.1246 - accuracy: 0.9616 - val_loss: 0.1518 - val_accuracy: 0.9452\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1252 - accuracy: 0.9614 - val_loss: 0.1540 - val_accuracy: 0.9429\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1224 - accuracy: 0.9623 - val_loss: 0.1493 - val_accuracy: 0.9476\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1220 - accuracy: 0.9624 - val_loss: 0.1494 - val_accuracy: 0.9452\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1223 - accuracy: 0.9625 - val_loss: 0.1494 - val_accuracy: 0.9452\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1234 - accuracy: 0.9613 - val_loss: 0.1521 - val_accuracy: 0.9452\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1215 - accuracy: 0.9626 - val_loss: 0.1541 - val_accuracy: 0.9452\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1195 - accuracy: 0.9631 - val_loss: 0.1536 - val_accuracy: 0.9452\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1220 - accuracy: 0.9619 - val_loss: 0.1521 - val_accuracy: 0.9524\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 14s 21ms/step - loss: 0.1218 - accuracy: 0.9627 - val_loss: 0.1436 - val_accuracy: 0.9524\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1213 - accuracy: 0.9621 - val_loss: 0.1526 - val_accuracy: 0.9476\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1220 - accuracy: 0.9622 - val_loss: 0.1454 - val_accuracy: 0.9524\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1212 - accuracy: 0.9628 - val_loss: 0.1448 - val_accuracy: 0.9500\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 14s 21ms/step - loss: 0.1223 - accuracy: 0.9626 - val_loss: 0.1409 - val_accuracy: 0.9524\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1195 - accuracy: 0.9635 - val_loss: 0.1473 - val_accuracy: 0.9500\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1231 - accuracy: 0.9618 - val_loss: 0.1473 - val_accuracy: 0.9476\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1198 - accuracy: 0.9632 - val_loss: 0.1503 - val_accuracy: 0.9500\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1231 - accuracy: 0.9627 - val_loss: 0.1469 - val_accuracy: 0.9500\n",
      "Epoch 20/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1202 - accuracy: 0.9623 - val_loss: 0.1450 - val_accuracy: 0.9524\n",
      "Epoch 21/100\n",
      "704/704 [==============================] - 14s 20ms/step - loss: 0.1185 - accuracy: 0.9626 - val_loss: 0.1434 - val_accuracy: 0.9524\n",
      "Epoch 22/100\n",
      "704/704 [==============================] - 14s 21ms/step - loss: 0.1198 - accuracy: 0.9629 - val_loss: 0.1435 - val_accuracy: 0.9524\n",
      "Epoch 23/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1185 - accuracy: 0.9645 - val_loss: 0.1405 - val_accuracy: 0.9524\n",
      "Epoch 24/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1201 - accuracy: 0.9622 - val_loss: 0.1379 - val_accuracy: 0.9524\n",
      "Epoch 25/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1202 - accuracy: 0.9624 - val_loss: 0.1403 - val_accuracy: 0.9524\n",
      "Epoch 26/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1203 - accuracy: 0.9626 - val_loss: 0.1354 - val_accuracy: 0.9524\n",
      "Epoch 27/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1200 - accuracy: 0.9632 - val_loss: 0.1372 - val_accuracy: 0.9524\n",
      "Epoch 28/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1202 - accuracy: 0.9639 - val_loss: 0.1308 - val_accuracy: 0.9571\n",
      "Epoch 29/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1183 - accuracy: 0.9628 - val_loss: 0.1361 - val_accuracy: 0.9595\n",
      "Epoch 30/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1214 - accuracy: 0.9623 - val_loss: 0.1342 - val_accuracy: 0.9524\n",
      "Epoch 31/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1199 - accuracy: 0.9632 - val_loss: 0.1340 - val_accuracy: 0.9548\n",
      "Epoch 32/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1201 - accuracy: 0.9620 - val_loss: 0.1315 - val_accuracy: 0.9548\n",
      "Epoch 33/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1155 - accuracy: 0.9641 - val_loss: 0.1310 - val_accuracy: 0.9548\n",
      "Epoch 34/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1200 - accuracy: 0.9630 - val_loss: 0.1328 - val_accuracy: 0.9571\n",
      "Epoch 35/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1184 - accuracy: 0.9633 - val_loss: 0.1314 - val_accuracy: 0.9548\n",
      "Epoch 36/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1182 - accuracy: 0.9632 - val_loss: 0.1309 - val_accuracy: 0.9548\n",
      "Epoch 37/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1171 - accuracy: 0.9634 - val_loss: 0.1328 - val_accuracy: 0.9548\n",
      "Epoch 38/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1213 - accuracy: 0.9629 - val_loss: 0.1288 - val_accuracy: 0.9571\n",
      "Epoch 39/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1203 - accuracy: 0.9630 - val_loss: 0.1360 - val_accuracy: 0.9548\n",
      "Epoch 40/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1181 - accuracy: 0.9638 - val_loss: 0.1284 - val_accuracy: 0.9595\n",
      "Epoch 41/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1198 - accuracy: 0.9636 - val_loss: 0.1247 - val_accuracy: 0.9595\n",
      "Epoch 42/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1210 - accuracy: 0.9625 - val_loss: 0.1288 - val_accuracy: 0.9571\n",
      "Epoch 43/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1169 - accuracy: 0.9631 - val_loss: 0.1271 - val_accuracy: 0.9571\n",
      "Epoch 44/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1195 - accuracy: 0.9629 - val_loss: 0.1239 - val_accuracy: 0.9595\n",
      "Epoch 45/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1194 - accuracy: 0.9633 - val_loss: 0.1229 - val_accuracy: 0.9595\n",
      "Epoch 46/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1172 - accuracy: 0.9633 - val_loss: 0.1253 - val_accuracy: 0.9595\n",
      "Epoch 47/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1158 - accuracy: 0.9637 - val_loss: 0.1225 - val_accuracy: 0.9595\n",
      "Epoch 48/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1166 - accuracy: 0.9636 - val_loss: 0.1239 - val_accuracy: 0.9619\n",
      "Epoch 49/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1192 - accuracy: 0.9624 - val_loss: 0.1242 - val_accuracy: 0.9595\n",
      "Epoch 50/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1196 - accuracy: 0.9630 - val_loss: 0.1250 - val_accuracy: 0.9571\n",
      "Epoch 51/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1165 - accuracy: 0.9637 - val_loss: 0.1214 - val_accuracy: 0.9571\n",
      "Epoch 52/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1149 - accuracy: 0.9650 - val_loss: 0.1228 - val_accuracy: 0.9595\n",
      "Epoch 53/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1160 - accuracy: 0.9642 - val_loss: 0.1212 - val_accuracy: 0.9619\n",
      "Epoch 54/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1175 - accuracy: 0.9641 - val_loss: 0.1207 - val_accuracy: 0.9619\n",
      "Epoch 55/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1175 - accuracy: 0.9636 - val_loss: 0.1212 - val_accuracy: 0.9619\n",
      "Epoch 56/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1160 - accuracy: 0.9642 - val_loss: 0.1186 - val_accuracy: 0.9619\n",
      "Epoch 57/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1174 - accuracy: 0.9639 - val_loss: 0.1222 - val_accuracy: 0.9619\n",
      "Epoch 58/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1203 - accuracy: 0.9633 - val_loss: 0.1215 - val_accuracy: 0.9619\n",
      "Epoch 59/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1191 - accuracy: 0.9626 - val_loss: 0.1158 - val_accuracy: 0.9619\n",
      "Epoch 60/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1182 - accuracy: 0.9634 - val_loss: 0.1162 - val_accuracy: 0.9619\n",
      "Epoch 61/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1171 - accuracy: 0.9637 - val_loss: 0.1167 - val_accuracy: 0.9619\n",
      "Epoch 62/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1174 - accuracy: 0.9641 - val_loss: 0.1162 - val_accuracy: 0.9619\n",
      "Epoch 63/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1148 - accuracy: 0.9642 - val_loss: 0.1161 - val_accuracy: 0.9619\n",
      "Epoch 64/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1174 - accuracy: 0.9633 - val_loss: 0.1166 - val_accuracy: 0.9619\n",
      "Epoch 65/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1165 - accuracy: 0.9630 - val_loss: 0.1167 - val_accuracy: 0.9619\n",
      "Epoch 66/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1143 - accuracy: 0.9644 - val_loss: 0.1187 - val_accuracy: 0.9619\n",
      "Epoch 67/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1144 - accuracy: 0.9642 - val_loss: 0.1171 - val_accuracy: 0.9619\n",
      "Epoch 68/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1154 - accuracy: 0.9636 - val_loss: 0.1160 - val_accuracy: 0.9619\n",
      "Epoch 69/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1162 - accuracy: 0.9642 - val_loss: 0.1146 - val_accuracy: 0.9619\n",
      "Epoch 70/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1181 - accuracy: 0.9637 - val_loss: 0.1126 - val_accuracy: 0.9619\n",
      "Epoch 71/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1166 - accuracy: 0.9634 - val_loss: 0.1172 - val_accuracy: 0.9619\n",
      "Epoch 72/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1150 - accuracy: 0.9641 - val_loss: 0.1118 - val_accuracy: 0.9619\n",
      "Epoch 73/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1166 - accuracy: 0.9637 - val_loss: 0.1098 - val_accuracy: 0.9619\n",
      "Epoch 74/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1143 - accuracy: 0.9649 - val_loss: 0.1131 - val_accuracy: 0.9619\n",
      "Epoch 75/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1150 - accuracy: 0.9640 - val_loss: 0.1117 - val_accuracy: 0.9619\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1138 - accuracy: 0.9650 - val_loss: 0.1084 - val_accuracy: 0.9643\n",
      "Epoch 77/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1173 - accuracy: 0.9640 - val_loss: 0.1126 - val_accuracy: 0.9619\n",
      "Epoch 78/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1162 - accuracy: 0.9639 - val_loss: 0.1093 - val_accuracy: 0.9643\n",
      "Epoch 79/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1167 - accuracy: 0.9641 - val_loss: 0.1101 - val_accuracy: 0.9643\n",
      "Epoch 80/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1187 - accuracy: 0.9635 - val_loss: 0.1061 - val_accuracy: 0.9643\n",
      "Epoch 81/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1159 - accuracy: 0.9644 - val_loss: 0.1092 - val_accuracy: 0.9643\n",
      "Epoch 82/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1142 - accuracy: 0.9645 - val_loss: 0.1109 - val_accuracy: 0.9619\n",
      "Epoch 83/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1140 - accuracy: 0.9647 - val_loss: 0.1109 - val_accuracy: 0.9643\n",
      "Epoch 84/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1127 - accuracy: 0.9651 - val_loss: 0.1077 - val_accuracy: 0.9643\n",
      "Epoch 85/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1145 - accuracy: 0.9644 - val_loss: 0.1102 - val_accuracy: 0.9643\n",
      "Epoch 86/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1141 - accuracy: 0.9654 - val_loss: 0.1082 - val_accuracy: 0.9643\n",
      "Epoch 87/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1165 - accuracy: 0.9642 - val_loss: 0.1037 - val_accuracy: 0.9643\n",
      "Epoch 88/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1128 - accuracy: 0.9643 - val_loss: 0.1092 - val_accuracy: 0.9643\n",
      "Epoch 89/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1164 - accuracy: 0.9649 - val_loss: 0.1038 - val_accuracy: 0.9643\n",
      "Epoch 90/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1162 - accuracy: 0.9635 - val_loss: 0.1061 - val_accuracy: 0.9643\n",
      "Epoch 91/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1155 - accuracy: 0.9641 - val_loss: 0.1061 - val_accuracy: 0.9667\n",
      "Epoch 92/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1148 - accuracy: 0.9640 - val_loss: 0.1080 - val_accuracy: 0.9667\n",
      "Epoch 93/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1135 - accuracy: 0.9648 - val_loss: 0.1043 - val_accuracy: 0.9643\n",
      "Epoch 94/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1128 - accuracy: 0.9658 - val_loss: 0.1045 - val_accuracy: 0.9643\n",
      "Epoch 95/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1159 - accuracy: 0.9637 - val_loss: 0.1047 - val_accuracy: 0.9667\n",
      "Epoch 96/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1146 - accuracy: 0.9643 - val_loss: 0.1044 - val_accuracy: 0.9643\n",
      "Epoch 97/100\n",
      "704/704 [==============================] - 15s 21ms/step - loss: 0.1140 - accuracy: 0.9645 - val_loss: 0.1103 - val_accuracy: 0.9643\n",
      "Epoch 98/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1166 - accuracy: 0.9641 - val_loss: 0.1046 - val_accuracy: 0.9643\n",
      "Epoch 99/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1136 - accuracy: 0.9641 - val_loss: 0.1073 - val_accuracy: 0.9643\n",
      "Epoch 100/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1143 - accuracy: 0.9646 - val_loss: 0.1015 - val_accuracy: 0.9667\n",
      "model_2 재학습 2번 완료\n",
      "model_2 저장\n",
      "\n",
      "WARNING:tensorflow:From /home/jiyeong/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 2.2031 - accuracy: 0.3874 - val_loss: 1.2622 - val_accuracy: 0.4310\n",
      "Epoch 2/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 1.9543 - accuracy: 0.4934 - val_loss: 1.1884 - val_accuracy: 0.4810\n",
      "Epoch 3/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 1.8139 - accuracy: 0.5464 - val_loss: 1.0877 - val_accuracy: 0.5500\n",
      "Epoch 4/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 1.6622 - accuracy: 0.5992 - val_loss: 0.9409 - val_accuracy: 0.6238\n",
      "Epoch 5/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 1.5311 - accuracy: 0.6434 - val_loss: 0.8496 - val_accuracy: 0.6833\n",
      "Epoch 6/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 1.4116 - accuracy: 0.6763 - val_loss: 0.7664 - val_accuracy: 0.7048\n",
      "Epoch 7/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 1.3139 - accuracy: 0.7025 - val_loss: 0.7025 - val_accuracy: 0.7262\n",
      "Epoch 8/1000\n",
      "703/703 [==============================] - 18s 25ms/step - loss: 1.2277 - accuracy: 0.7275 - val_loss: 0.6421 - val_accuracy: 0.7405\n",
      "Epoch 9/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 1.1646 - accuracy: 0.7424 - val_loss: 0.6597 - val_accuracy: 0.7405\n",
      "Epoch 10/1000\n",
      "703/703 [==============================] - 18s 26ms/step - loss: 1.1054 - accuracy: 0.7573 - val_loss: 0.6323 - val_accuracy: 0.7429\n",
      "Epoch 11/1000\n",
      "703/703 [==============================] - 19s 27ms/step - loss: 1.0547 - accuracy: 0.7700 - val_loss: 0.6197 - val_accuracy: 0.7786\n",
      "Epoch 12/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 1.0052 - accuracy: 0.7821 - val_loss: 0.6136 - val_accuracy: 0.7738\n",
      "Epoch 13/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.9694 - accuracy: 0.7918 - val_loss: 0.5500 - val_accuracy: 0.8071\n",
      "Epoch 14/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.9222 - accuracy: 0.8007 - val_loss: 0.5740 - val_accuracy: 0.7905\n",
      "Epoch 15/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.8912 - accuracy: 0.8094 - val_loss: 0.5619 - val_accuracy: 0.8095\n",
      "Epoch 16/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.8634 - accuracy: 0.8146 - val_loss: 0.5542 - val_accuracy: 0.8048\n",
      "Epoch 17/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.8357 - accuracy: 0.8213 - val_loss: 0.5202 - val_accuracy: 0.8190\n",
      "Epoch 18/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.8156 - accuracy: 0.8262 - val_loss: 0.5480 - val_accuracy: 0.8214\n",
      "Epoch 19/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.7963 - accuracy: 0.8297 - val_loss: 0.5255 - val_accuracy: 0.8190\n",
      "Epoch 20/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.7704 - accuracy: 0.8376 - val_loss: 0.5042 - val_accuracy: 0.8119\n",
      "Epoch 21/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.7525 - accuracy: 0.8399 - val_loss: 0.5113 - val_accuracy: 0.8214\n",
      "Epoch 22/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.7227 - accuracy: 0.8473 - val_loss: 0.5262 - val_accuracy: 0.8286\n",
      "Epoch 23/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.7110 - accuracy: 0.8490 - val_loss: 0.4998 - val_accuracy: 0.8310\n",
      "Epoch 24/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.7016 - accuracy: 0.8516 - val_loss: 0.4946 - val_accuracy: 0.8310\n",
      "Epoch 25/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.6775 - accuracy: 0.8575 - val_loss: 0.5120 - val_accuracy: 0.8286\n",
      "Epoch 26/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.6668 - accuracy: 0.8587 - val_loss: 0.5020 - val_accuracy: 0.8405\n",
      "Epoch 27/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.6520 - accuracy: 0.8626 - val_loss: 0.4546 - val_accuracy: 0.8452\n",
      "Epoch 28/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.6434 - accuracy: 0.8634 - val_loss: 0.4831 - val_accuracy: 0.8476\n",
      "Epoch 29/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.6410 - accuracy: 0.8663 - val_loss: 0.5136 - val_accuracy: 0.8429\n",
      "Epoch 30/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.6219 - accuracy: 0.8716 - val_loss: 0.5126 - val_accuracy: 0.8310\n",
      "Epoch 31/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.6169 - accuracy: 0.8722 - val_loss: 0.4912 - val_accuracy: 0.8548\n",
      "Epoch 32/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.6030 - accuracy: 0.8741 - val_loss: 0.4642 - val_accuracy: 0.8500\n",
      "Epoch 33/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.5865 - accuracy: 0.8772 - val_loss: 0.4610 - val_accuracy: 0.8452\n",
      "Epoch 34/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.5889 - accuracy: 0.8780 - val_loss: 0.4343 - val_accuracy: 0.8548\n",
      "Epoch 35/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.5723 - accuracy: 0.8816 - val_loss: 0.4655 - val_accuracy: 0.8405\n",
      "Epoch 36/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.5625 - accuracy: 0.8821 - val_loss: 0.4376 - val_accuracy: 0.8690\n",
      "Epoch 37/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.5570 - accuracy: 0.8840 - val_loss: 0.4563 - val_accuracy: 0.8643\n",
      "Epoch 38/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.5446 - accuracy: 0.8874 - val_loss: 0.4577 - val_accuracy: 0.8690\n",
      "Epoch 39/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.5373 - accuracy: 0.8878 - val_loss: 0.4612 - val_accuracy: 0.8571\n",
      "Epoch 40/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.5364 - accuracy: 0.8884 - val_loss: 0.4965 - val_accuracy: 0.8667\n",
      "Epoch 41/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.5238 - accuracy: 0.8923 - val_loss: 0.4761 - val_accuracy: 0.8690\n",
      "Epoch 42/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.5173 - accuracy: 0.8914 - val_loss: 0.4954 - val_accuracy: 0.8429\n",
      "Epoch 43/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.5193 - accuracy: 0.8930 - val_loss: 0.4244 - val_accuracy: 0.8738\n",
      "Epoch 44/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.5050 - accuracy: 0.8939 - val_loss: 0.4725 - val_accuracy: 0.8643\n",
      "Epoch 45/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.5079 - accuracy: 0.8953 - val_loss: 0.4731 - val_accuracy: 0.8619\n",
      "Epoch 46/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4974 - accuracy: 0.8956 - val_loss: 0.4748 - val_accuracy: 0.8595\n",
      "Epoch 47/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4915 - accuracy: 0.8991 - val_loss: 0.4670 - val_accuracy: 0.8762\n",
      "Epoch 48/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4904 - accuracy: 0.8974 - val_loss: 0.4264 - val_accuracy: 0.8714\n",
      "Epoch 49/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4807 - accuracy: 0.8995 - val_loss: 0.4432 - val_accuracy: 0.8738\n",
      "Epoch 50/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4743 - accuracy: 0.9019 - val_loss: 0.4141 - val_accuracy: 0.8714\n",
      "Epoch 51/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4634 - accuracy: 0.9036 - val_loss: 0.4512 - val_accuracy: 0.8667\n",
      "Epoch 52/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4701 - accuracy: 0.9025 - val_loss: 0.4908 - val_accuracy: 0.8667\n",
      "Epoch 53/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4582 - accuracy: 0.9060 - val_loss: 0.4325 - val_accuracy: 0.8857\n",
      "Epoch 54/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4553 - accuracy: 0.9062 - val_loss: 0.4656 - val_accuracy: 0.8571\n",
      "Epoch 55/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4563 - accuracy: 0.9056 - val_loss: 0.4265 - val_accuracy: 0.8714\n",
      "Epoch 56/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4513 - accuracy: 0.9072 - val_loss: 0.4485 - val_accuracy: 0.8905\n",
      "Epoch 57/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4467 - accuracy: 0.9081 - val_loss: 0.4283 - val_accuracy: 0.8881\n",
      "Epoch 58/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4385 - accuracy: 0.9085 - val_loss: 0.4396 - val_accuracy: 0.8738\n",
      "Epoch 59/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4430 - accuracy: 0.9099 - val_loss: 0.4583 - val_accuracy: 0.8738\n",
      "Epoch 60/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4308 - accuracy: 0.9106 - val_loss: 0.4293 - val_accuracy: 0.8762\n",
      "Epoch 61/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4234 - accuracy: 0.9127 - val_loss: 0.4347 - val_accuracy: 0.8833\n",
      "Epoch 62/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4277 - accuracy: 0.9117 - val_loss: 0.4460 - val_accuracy: 0.8905\n",
      "Epoch 63/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4242 - accuracy: 0.9119 - val_loss: 0.4228 - val_accuracy: 0.8857\n",
      "Epoch 64/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4162 - accuracy: 0.9142 - val_loss: 0.4341 - val_accuracy: 0.8714\n",
      "Epoch 65/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4154 - accuracy: 0.9146 - val_loss: 0.4227 - val_accuracy: 0.8881\n",
      "Epoch 66/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4100 - accuracy: 0.9154 - val_loss: 0.4100 - val_accuracy: 0.8786\n",
      "Epoch 67/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3994 - accuracy: 0.9181 - val_loss: 0.4094 - val_accuracy: 0.8881\n",
      "Epoch 68/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4031 - accuracy: 0.9169 - val_loss: 0.4036 - val_accuracy: 0.8810\n",
      "Epoch 69/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4026 - accuracy: 0.9172 - val_loss: 0.4529 - val_accuracy: 0.8905\n",
      "Epoch 70/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3946 - accuracy: 0.9180 - val_loss: 0.4029 - val_accuracy: 0.8905\n",
      "Epoch 71/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.4037 - accuracy: 0.9188 - val_loss: 0.4530 - val_accuracy: 0.8786\n",
      "Epoch 72/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3923 - accuracy: 0.9197 - val_loss: 0.4894 - val_accuracy: 0.8857\n",
      "Epoch 73/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3905 - accuracy: 0.9200 - val_loss: 0.4569 - val_accuracy: 0.8667\n",
      "Epoch 74/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3902 - accuracy: 0.9201 - val_loss: 0.4617 - val_accuracy: 0.8857\n",
      "Epoch 75/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3854 - accuracy: 0.9204 - val_loss: 0.4616 - val_accuracy: 0.8881\n",
      "Epoch 76/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3830 - accuracy: 0.9214 - val_loss: 0.3994 - val_accuracy: 0.8929\n",
      "Epoch 77/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3780 - accuracy: 0.9214 - val_loss: 0.4307 - val_accuracy: 0.8905\n",
      "Epoch 78/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3793 - accuracy: 0.9225 - val_loss: 0.3746 - val_accuracy: 0.8905\n",
      "Epoch 79/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3737 - accuracy: 0.9240 - val_loss: 0.4053 - val_accuracy: 0.8929\n",
      "Epoch 80/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3753 - accuracy: 0.9231 - val_loss: 0.4546 - val_accuracy: 0.8810\n",
      "Epoch 81/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3713 - accuracy: 0.9223 - val_loss: 0.4130 - val_accuracy: 0.8810\n",
      "Epoch 82/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3657 - accuracy: 0.9250 - val_loss: 0.4280 - val_accuracy: 0.8810\n",
      "Epoch 83/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3728 - accuracy: 0.9242 - val_loss: 0.4106 - val_accuracy: 0.9000\n",
      "Epoch 84/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3680 - accuracy: 0.9246 - val_loss: 0.4249 - val_accuracy: 0.8952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3659 - accuracy: 0.9247 - val_loss: 0.4095 - val_accuracy: 0.8881\n",
      "Epoch 86/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3663 - accuracy: 0.9250 - val_loss: 0.4385 - val_accuracy: 0.8810\n",
      "Epoch 87/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3548 - accuracy: 0.9279 - val_loss: 0.4421 - val_accuracy: 0.8810\n",
      "Epoch 88/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3628 - accuracy: 0.9258 - val_loss: 0.4915 - val_accuracy: 0.8810\n",
      "Epoch 89/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3614 - accuracy: 0.9252 - val_loss: 0.4191 - val_accuracy: 0.8857\n",
      "Epoch 90/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3595 - accuracy: 0.9268 - val_loss: 0.3981 - val_accuracy: 0.8810\n",
      "Epoch 91/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3575 - accuracy: 0.9283 - val_loss: 0.4469 - val_accuracy: 0.8738\n",
      "Epoch 92/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3521 - accuracy: 0.9285 - val_loss: 0.4676 - val_accuracy: 0.8810\n",
      "Epoch 93/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3537 - accuracy: 0.9292 - val_loss: 0.4489 - val_accuracy: 0.8929\n",
      "Epoch 94/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3468 - accuracy: 0.9298 - val_loss: 0.4047 - val_accuracy: 0.8881\n",
      "Epoch 95/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3478 - accuracy: 0.9292 - val_loss: 0.4543 - val_accuracy: 0.8690\n",
      "Epoch 96/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3396 - accuracy: 0.9300 - val_loss: 0.4370 - val_accuracy: 0.8810\n",
      "Epoch 97/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3447 - accuracy: 0.9284 - val_loss: 0.4834 - val_accuracy: 0.8833\n",
      "Epoch 98/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.3490 - accuracy: 0.9287 - val_loss: 0.4815 - val_accuracy: 0.8786\n",
      "Epoch 99/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.3432 - accuracy: 0.9294 - val_loss: 0.4216 - val_accuracy: 0.8833\n",
      "Epoch 100/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3484 - accuracy: 0.9298 - val_loss: 0.3760 - val_accuracy: 0.8929\n",
      "Epoch 101/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.3367 - accuracy: 0.9307 - val_loss: 0.4279 - val_accuracy: 0.8905\n",
      "Epoch 102/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.3339 - accuracy: 0.9300 - val_loss: 0.4375 - val_accuracy: 0.8881\n",
      "Epoch 103/1000\n",
      "703/703 [==============================] - 18s 25ms/step - loss: 0.3334 - accuracy: 0.9317 - val_loss: 0.4493 - val_accuracy: 0.8929\n",
      "Epoch 104/1000\n",
      "703/703 [==============================] - 22s 32ms/step - loss: 0.3012 - accuracy: 0.9375 - val_loss: 0.4298 - val_accuracy: 0.8952\n",
      "Epoch 105/1000\n",
      "703/703 [==============================] - 19s 27ms/step - loss: 0.2848 - accuracy: 0.9411 - val_loss: 0.4599 - val_accuracy: 0.8929\n",
      "Epoch 106/1000\n",
      "703/703 [==============================] - 20s 28ms/step - loss: 0.2832 - accuracy: 0.9424 - val_loss: 0.4160 - val_accuracy: 0.8905\n",
      "Epoch 107/1000\n",
      "703/703 [==============================] - 17s 25ms/step - loss: 0.2798 - accuracy: 0.9426 - val_loss: 0.4387 - val_accuracy: 0.8857\n",
      "Epoch 108/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.2788 - accuracy: 0.9425 - val_loss: 0.4076 - val_accuracy: 0.9000\n",
      "Epoch 109/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.2686 - accuracy: 0.9446 - val_loss: 0.4508 - val_accuracy: 0.8952\n",
      "Epoch 110/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2690 - accuracy: 0.9455 - val_loss: 0.4359 - val_accuracy: 0.8833\n",
      "Epoch 111/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.2671 - accuracy: 0.9461 - val_loss: 0.4039 - val_accuracy: 0.8929\n",
      "Epoch 112/1000\n",
      "703/703 [==============================] - 18s 26ms/step - loss: 0.2667 - accuracy: 0.9461 - val_loss: 0.3943 - val_accuracy: 0.8905\n",
      "Epoch 113/1000\n",
      "703/703 [==============================] - 17s 25ms/step - loss: 0.2628 - accuracy: 0.9467 - val_loss: 0.4555 - val_accuracy: 0.8881\n",
      "Epoch 114/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.2583 - accuracy: 0.9477 - val_loss: 0.4273 - val_accuracy: 0.8905\n",
      "Epoch 115/1000\n",
      "703/703 [==============================] - 18s 26ms/step - loss: 0.2635 - accuracy: 0.9471 - val_loss: 0.3985 - val_accuracy: 0.8952\n",
      "Epoch 116/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2528 - accuracy: 0.9481 - val_loss: 0.4384 - val_accuracy: 0.9000\n",
      "Epoch 117/1000\n",
      "703/703 [==============================] - 19s 27ms/step - loss: 0.2560 - accuracy: 0.9479 - val_loss: 0.4476 - val_accuracy: 0.8929\n",
      "Epoch 118/1000\n",
      "703/703 [==============================] - 20s 29ms/step - loss: 0.2574 - accuracy: 0.9464 - val_loss: 0.4219 - val_accuracy: 0.9048\n",
      "Epoch 119/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.2482 - accuracy: 0.9489 - val_loss: 0.4335 - val_accuracy: 0.8929\n",
      "Epoch 120/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.2559 - accuracy: 0.9484 - val_loss: 0.4251 - val_accuracy: 0.8952\n",
      "Epoch 121/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.2501 - accuracy: 0.9487 - val_loss: 0.4417 - val_accuracy: 0.9000\n",
      "Epoch 122/1000\n",
      "703/703 [==============================] - 17s 25ms/step - loss: 0.2517 - accuracy: 0.9487 - val_loss: 0.4387 - val_accuracy: 0.8976\n",
      "Epoch 123/1000\n",
      "703/703 [==============================] - 21s 30ms/step - loss: 0.2479 - accuracy: 0.9492 - val_loss: 0.4242 - val_accuracy: 0.8976\n",
      "Epoch 124/1000\n",
      "703/703 [==============================] - 18s 25ms/step - loss: 0.2414 - accuracy: 0.9506 - val_loss: 0.4315 - val_accuracy: 0.9000\n",
      "Epoch 125/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2483 - accuracy: 0.9495 - val_loss: 0.4524 - val_accuracy: 0.8976\n",
      "Epoch 126/1000\n",
      "703/703 [==============================] - 18s 25ms/step - loss: 0.2427 - accuracy: 0.9507 - val_loss: 0.4352 - val_accuracy: 0.9000\n",
      "Epoch 127/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.2444 - accuracy: 0.9486 - val_loss: 0.4472 - val_accuracy: 0.8952\n",
      "Epoch 128/1000\n",
      "703/703 [==============================] - 17s 25ms/step - loss: 0.2422 - accuracy: 0.9499 - val_loss: 0.4331 - val_accuracy: 0.8905\n",
      "Epoch 129/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.2402 - accuracy: 0.9513 - val_loss: 0.4101 - val_accuracy: 0.9024\n",
      "Epoch 130/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2420 - accuracy: 0.9504 - val_loss: 0.4146 - val_accuracy: 0.8952\n",
      "Epoch 131/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2346 - accuracy: 0.9523 - val_loss: 0.4127 - val_accuracy: 0.9024\n",
      "Epoch 132/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.2367 - accuracy: 0.9513 - val_loss: 0.4053 - val_accuracy: 0.9071\n",
      "Epoch 133/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2419 - accuracy: 0.9501 - val_loss: 0.4133 - val_accuracy: 0.8976\n",
      "Epoch 134/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.2313 - accuracy: 0.9528 - val_loss: 0.4153 - val_accuracy: 0.9000\n",
      "Epoch 135/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2357 - accuracy: 0.9519 - val_loss: 0.4075 - val_accuracy: 0.9024\n",
      "Epoch 136/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2313 - accuracy: 0.9534 - val_loss: 0.4339 - val_accuracy: 0.8952\n",
      "Epoch 137/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2291 - accuracy: 0.9532 - val_loss: 0.4577 - val_accuracy: 0.8929\n",
      "Epoch 138/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2303 - accuracy: 0.9530 - val_loss: 0.4260 - val_accuracy: 0.8976\n",
      "Epoch 139/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2299 - accuracy: 0.9527 - val_loss: 0.4241 - val_accuracy: 0.8976\n",
      "Epoch 140/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2304 - accuracy: 0.9531 - val_loss: 0.4403 - val_accuracy: 0.9024\n",
      "Epoch 141/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2312 - accuracy: 0.9527 - val_loss: 0.3990 - val_accuracy: 0.8905\n",
      "Epoch 142/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2313 - accuracy: 0.9528 - val_loss: 0.4151 - val_accuracy: 0.8952\n",
      "Epoch 143/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2275 - accuracy: 0.9544 - val_loss: 0.3974 - val_accuracy: 0.8905\n",
      "Epoch 144/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.2236 - accuracy: 0.9539 - val_loss: 0.4464 - val_accuracy: 0.8976\n",
      "Epoch 145/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2264 - accuracy: 0.9545 - val_loss: 0.4122 - val_accuracy: 0.9000\n",
      "Epoch 146/1000\n",
      "703/703 [==============================] - 18s 26ms/step - loss: 0.2200 - accuracy: 0.9561 - val_loss: 0.4300 - val_accuracy: 0.9071\n",
      "Epoch 147/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2240 - accuracy: 0.9548 - val_loss: 0.4156 - val_accuracy: 0.9000\n",
      "Epoch 148/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.2213 - accuracy: 0.9541 - val_loss: 0.4258 - val_accuracy: 0.9000\n",
      "Epoch 149/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.2219 - accuracy: 0.9544 - val_loss: 0.4581 - val_accuracy: 0.8952\n",
      "Epoch 150/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.2218 - accuracy: 0.9550 - val_loss: 0.4477 - val_accuracy: 0.9024\n",
      "Epoch 151/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.2225 - accuracy: 0.9545 - val_loss: 0.3953 - val_accuracy: 0.9048\n",
      "Epoch 152/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.2165 - accuracy: 0.9556 - val_loss: 0.4762 - val_accuracy: 0.8976\n",
      "Epoch 153/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.2090 - accuracy: 0.9573 - val_loss: 0.4228 - val_accuracy: 0.9048\n",
      "Epoch 154/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1961 - accuracy: 0.9589 - val_loss: 0.4275 - val_accuracy: 0.9000\n",
      "Epoch 155/1000\n",
      "703/703 [==============================] - 17s 25ms/step - loss: 0.2019 - accuracy: 0.9592 - val_loss: 0.4093 - val_accuracy: 0.9048\n",
      "Epoch 156/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1997 - accuracy: 0.9598 - val_loss: 0.4200 - val_accuracy: 0.9071\n",
      "Epoch 157/1000\n",
      "703/703 [==============================] - 19s 27ms/step - loss: 0.1956 - accuracy: 0.9593 - val_loss: 0.4312 - val_accuracy: 0.9048\n",
      "Epoch 158/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1971 - accuracy: 0.9596 - val_loss: 0.4400 - val_accuracy: 0.8976\n",
      "Epoch 159/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1951 - accuracy: 0.9606 - val_loss: 0.4560 - val_accuracy: 0.9000\n",
      "Epoch 160/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.1927 - accuracy: 0.9603 - val_loss: 0.4138 - val_accuracy: 0.8976\n",
      "Epoch 161/1000\n",
      "703/703 [==============================] - 18s 25ms/step - loss: 0.1957 - accuracy: 0.9608 - val_loss: 0.3935 - val_accuracy: 0.8976\n",
      "Epoch 162/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1880 - accuracy: 0.9612 - val_loss: 0.4065 - val_accuracy: 0.8976\n",
      "Epoch 163/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1916 - accuracy: 0.9615 - val_loss: 0.4111 - val_accuracy: 0.9000\n",
      "Epoch 164/1000\n",
      "703/703 [==============================] - 18s 26ms/step - loss: 0.1823 - accuracy: 0.9622 - val_loss: 0.4340 - val_accuracy: 0.9071\n",
      "Epoch 165/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1890 - accuracy: 0.9613 - val_loss: 0.4279 - val_accuracy: 0.9000\n",
      "Epoch 166/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1862 - accuracy: 0.9620 - val_loss: 0.4314 - val_accuracy: 0.8976\n",
      "Epoch 167/1000\n",
      "703/703 [==============================] - 18s 25ms/step - loss: 0.1844 - accuracy: 0.9627 - val_loss: 0.4567 - val_accuracy: 0.9095\n",
      "Epoch 168/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1886 - accuracy: 0.9620 - val_loss: 0.4198 - val_accuracy: 0.9071\n",
      "Epoch 169/1000\n",
      "703/703 [==============================] - 19s 27ms/step - loss: 0.1821 - accuracy: 0.9633 - val_loss: 0.4390 - val_accuracy: 0.9024\n",
      "Epoch 170/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1829 - accuracy: 0.9631 - val_loss: 0.4461 - val_accuracy: 0.8952\n",
      "Epoch 171/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1826 - accuracy: 0.9628 - val_loss: 0.4352 - val_accuracy: 0.9000\n",
      "Epoch 172/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1913 - accuracy: 0.9617 - val_loss: 0.4325 - val_accuracy: 0.9000\n",
      "Epoch 173/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1853 - accuracy: 0.9627 - val_loss: 0.4330 - val_accuracy: 0.8976\n",
      "Epoch 174/1000\n",
      "703/703 [==============================] - 17s 25ms/step - loss: 0.1818 - accuracy: 0.9627 - val_loss: 0.4420 - val_accuracy: 0.8952\n",
      "Epoch 175/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1873 - accuracy: 0.9623 - val_loss: 0.4311 - val_accuracy: 0.9024\n",
      "Epoch 176/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.1769 - accuracy: 0.9631 - val_loss: 0.4634 - val_accuracy: 0.9000\n",
      "Epoch 177/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1807 - accuracy: 0.9629 - val_loss: 0.4788 - val_accuracy: 0.8905\n",
      "Epoch 178/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1822 - accuracy: 0.9624 - val_loss: 0.4257 - val_accuracy: 0.9048\n",
      "Epoch 179/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1799 - accuracy: 0.9634 - val_loss: 0.4330 - val_accuracy: 0.9000\n",
      "Epoch 180/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.1768 - accuracy: 0.9634 - val_loss: 0.4186 - val_accuracy: 0.9000\n",
      "Epoch 181/1000\n",
      "703/703 [==============================] - 17s 25ms/step - loss: 0.1775 - accuracy: 0.9630 - val_loss: 0.4748 - val_accuracy: 0.9000\n",
      "Epoch 182/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1766 - accuracy: 0.9632 - val_loss: 0.4473 - val_accuracy: 0.8976\n",
      "Epoch 183/1000\n",
      "703/703 [==============================] - 19s 27ms/step - loss: 0.1807 - accuracy: 0.9629 - val_loss: 0.4204 - val_accuracy: 0.9071\n",
      "Epoch 184/1000\n",
      "703/703 [==============================] - 18s 25ms/step - loss: 0.1754 - accuracy: 0.9641 - val_loss: 0.4250 - val_accuracy: 0.9048\n",
      "Epoch 185/1000\n",
      "703/703 [==============================] - 18s 25ms/step - loss: 0.1762 - accuracy: 0.9637 - val_loss: 0.4271 - val_accuracy: 0.9024\n",
      "Epoch 186/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1771 - accuracy: 0.9636 - val_loss: 0.4129 - val_accuracy: 0.9048\n",
      "Epoch 187/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1720 - accuracy: 0.9645 - val_loss: 0.4516 - val_accuracy: 0.9024\n",
      "Epoch 188/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1705 - accuracy: 0.9651 - val_loss: 0.4297 - val_accuracy: 0.8976\n",
      "Epoch 189/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1725 - accuracy: 0.9658 - val_loss: 0.4522 - val_accuracy: 0.8952\n",
      "Epoch 190/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.1670 - accuracy: 0.9651 - val_loss: 0.4536 - val_accuracy: 0.8952\n",
      "Epoch 191/1000\n",
      "703/703 [==============================] - 15s 21ms/step - loss: 0.1681 - accuracy: 0.9657 - val_loss: 0.4219 - val_accuracy: 0.9048\n",
      "Epoch 192/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1675 - accuracy: 0.9657 - val_loss: 0.4524 - val_accuracy: 0.9000\n",
      "Epoch 193/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1705 - accuracy: 0.9654 - val_loss: 0.4334 - val_accuracy: 0.9000\n",
      "Epoch 194/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1599 - accuracy: 0.9672 - val_loss: 0.4432 - val_accuracy: 0.8905\n",
      "Epoch 195/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1646 - accuracy: 0.9673 - val_loss: 0.4464 - val_accuracy: 0.9024\n",
      "Epoch 196/1000\n",
      "703/703 [==============================] - 19s 27ms/step - loss: 0.1654 - accuracy: 0.9670 - val_loss: 0.4433 - val_accuracy: 0.9048\n",
      "Epoch 197/1000\n",
      "703/703 [==============================] - 18s 25ms/step - loss: 0.1635 - accuracy: 0.9666 - val_loss: 0.4466 - val_accuracy: 0.9000\n",
      "Epoch 198/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1615 - accuracy: 0.9670 - val_loss: 0.4573 - val_accuracy: 0.8929\n",
      "Epoch 199/1000\n",
      "703/703 [==============================] - 19s 28ms/step - loss: 0.1660 - accuracy: 0.9663 - val_loss: 0.4454 - val_accuracy: 0.9000\n",
      "Epoch 200/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1625 - accuracy: 0.9663 - val_loss: 0.4446 - val_accuracy: 0.9071\n",
      "Epoch 201/1000\n",
      "703/703 [==============================] - 18s 25ms/step - loss: 0.1594 - accuracy: 0.9673 - val_loss: 0.4393 - val_accuracy: 0.9024\n",
      "Epoch 202/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1667 - accuracy: 0.9667 - val_loss: 0.4439 - val_accuracy: 0.9000\n",
      "Epoch 203/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1639 - accuracy: 0.9667 - val_loss: 0.4325 - val_accuracy: 0.8929\n",
      "Epoch 204/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1607 - accuracy: 0.9667 - val_loss: 0.4572 - val_accuracy: 0.9000\n",
      "Epoch 205/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1574 - accuracy: 0.9675 - val_loss: 0.4404 - val_accuracy: 0.9000\n",
      "Epoch 206/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1608 - accuracy: 0.9676 - val_loss: 0.4567 - val_accuracy: 0.8976\n",
      "Epoch 207/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1604 - accuracy: 0.9671 - val_loss: 0.4459 - val_accuracy: 0.9071\n",
      "Epoch 208/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1588 - accuracy: 0.9675 - val_loss: 0.4430 - val_accuracy: 0.9048\n",
      "Epoch 209/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1584 - accuracy: 0.9675 - val_loss: 0.4384 - val_accuracy: 0.9024\n",
      "Epoch 210/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1548 - accuracy: 0.9684 - val_loss: 0.4381 - val_accuracy: 0.9048\n",
      "Epoch 211/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1519 - accuracy: 0.9691 - val_loss: 0.4451 - val_accuracy: 0.9000\n",
      "Epoch 212/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1530 - accuracy: 0.9676 - val_loss: 0.4390 - val_accuracy: 0.9024\n",
      "Epoch 213/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1559 - accuracy: 0.9682 - val_loss: 0.4409 - val_accuracy: 0.9000\n",
      "Epoch 214/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1559 - accuracy: 0.9674 - val_loss: 0.4400 - val_accuracy: 0.8952\n",
      "Epoch 215/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1535 - accuracy: 0.9687 - val_loss: 0.4414 - val_accuracy: 0.8976\n",
      "Epoch 216/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.1521 - accuracy: 0.9691 - val_loss: 0.4367 - val_accuracy: 0.9000\n",
      "Epoch 217/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1505 - accuracy: 0.9689 - val_loss: 0.4488 - val_accuracy: 0.9000\n",
      "Epoch 218/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1575 - accuracy: 0.9679 - val_loss: 0.4290 - val_accuracy: 0.9000\n",
      "Epoch 219/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1498 - accuracy: 0.9699 - val_loss: 0.4372 - val_accuracy: 0.9000\n",
      "Epoch 220/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1527 - accuracy: 0.9683 - val_loss: 0.4366 - val_accuracy: 0.9024\n",
      "Epoch 221/1000\n",
      "703/703 [==============================] - 17s 24ms/step - loss: 0.1498 - accuracy: 0.9693 - val_loss: 0.4487 - val_accuracy: 0.9000\n",
      "Epoch 222/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1546 - accuracy: 0.9679 - val_loss: 0.4491 - val_accuracy: 0.8976\n",
      "Epoch 223/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1549 - accuracy: 0.9684 - val_loss: 0.4412 - val_accuracy: 0.9048\n",
      "Epoch 224/1000\n",
      "703/703 [==============================] - 15s 22ms/step - loss: 0.1537 - accuracy: 0.9688 - val_loss: 0.4453 - val_accuracy: 0.9024\n",
      "Epoch 225/1000\n",
      "703/703 [==============================] - 17s 25ms/step - loss: 0.1495 - accuracy: 0.9687 - val_loss: 0.4683 - val_accuracy: 0.9024\n",
      "Epoch 226/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.1496 - accuracy: 0.9695 - val_loss: 0.4610 - val_accuracy: 0.9024\n",
      "Epoch 227/1000\n",
      "703/703 [==============================] - 18s 26ms/step - loss: 0.1493 - accuracy: 0.9685 - val_loss: 0.4651 - val_accuracy: 0.8976\n",
      "Epoch 228/1000\n",
      "703/703 [==============================] - 18s 26ms/step - loss: 0.1502 - accuracy: 0.9689 - val_loss: 0.4536 - val_accuracy: 0.9000\n",
      "Epoch 229/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1502 - accuracy: 0.9700 - val_loss: 0.4608 - val_accuracy: 0.8976\n",
      "Epoch 230/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1513 - accuracy: 0.9695 - val_loss: 0.4567 - val_accuracy: 0.8929\n",
      "Epoch 231/1000\n",
      "703/703 [==============================] - 18s 26ms/step - loss: 0.1498 - accuracy: 0.9700 - val_loss: 0.4545 - val_accuracy: 0.9000\n",
      "Epoch 232/1000\n",
      "703/703 [==============================] - 17s 25ms/step - loss: 0.1483 - accuracy: 0.9696 - val_loss: 0.4557 - val_accuracy: 0.9000\n",
      "Epoch 233/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1554 - accuracy: 0.9692 - val_loss: 0.4406 - val_accuracy: 0.9000\n",
      "Epoch 234/1000\n",
      "703/703 [==============================] - 18s 26ms/step - loss: 0.1498 - accuracy: 0.9698 - val_loss: 0.4396 - val_accuracy: 0.9024\n",
      "Epoch 235/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1470 - accuracy: 0.9700 - val_loss: 0.4447 - val_accuracy: 0.9000\n",
      "Epoch 236/1000\n",
      "703/703 [==============================] - 18s 25ms/step - loss: 0.1495 - accuracy: 0.9690 - val_loss: 0.4450 - val_accuracy: 0.9024\n",
      "Epoch 237/1000\n",
      "703/703 [==============================] - 18s 25ms/step - loss: 0.1464 - accuracy: 0.9708 - val_loss: 0.4551 - val_accuracy: 0.9000\n",
      "Epoch 238/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1463 - accuracy: 0.9700 - val_loss: 0.4399 - val_accuracy: 0.9048\n",
      "Epoch 239/1000\n",
      "703/703 [==============================] - 16s 22ms/step - loss: 0.1482 - accuracy: 0.9698 - val_loss: 0.4444 - val_accuracy: 0.9000\n",
      "Epoch 240/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1517 - accuracy: 0.9698 - val_loss: 0.4452 - val_accuracy: 0.9000\n",
      "Epoch 241/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1475 - accuracy: 0.9697 - val_loss: 0.4441 - val_accuracy: 0.9024\n",
      "Epoch 242/1000\n",
      "703/703 [==============================] - 16s 23ms/step - loss: 0.1509 - accuracy: 0.9690 - val_loss: 0.4572 - val_accuracy: 0.9024\n",
      "Epoch 00242: early stopping\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4572 - accuracy: 0.9024\n",
      "model_3 loss : [0.45719778537750244, 0.9023809432983398]\n",
      "Epoch 1/100\n",
      "704/704 [==============================] - 18s 24ms/step - loss: 0.1235 - accuracy: 0.9643 - val_loss: 0.4235 - val_accuracy: 0.9024\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.1197 - accuracy: 0.9646 - val_loss: 0.3912 - val_accuracy: 0.9048\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1206 - accuracy: 0.9645 - val_loss: 0.3774 - val_accuracy: 0.9048\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1192 - accuracy: 0.9649 - val_loss: 0.3690 - val_accuracy: 0.9071\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1171 - accuracy: 0.9651 - val_loss: 0.3558 - val_accuracy: 0.9119\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1207 - accuracy: 0.9644 - val_loss: 0.3440 - val_accuracy: 0.9167\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1180 - accuracy: 0.9651 - val_loss: 0.3311 - val_accuracy: 0.9167\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1198 - accuracy: 0.9646 - val_loss: 0.3164 - val_accuracy: 0.9167\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1179 - accuracy: 0.9644 - val_loss: 0.3105 - val_accuracy: 0.9167\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1144 - accuracy: 0.9650 - val_loss: 0.3007 - val_accuracy: 0.9190\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.1170 - accuracy: 0.9647 - val_loss: 0.2992 - val_accuracy: 0.9214\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 18s 26ms/step - loss: 0.1161 - accuracy: 0.9649 - val_loss: 0.2859 - val_accuracy: 0.9238\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 18s 26ms/step - loss: 0.1163 - accuracy: 0.9651 - val_loss: 0.2854 - val_accuracy: 0.9214\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1194 - accuracy: 0.9642 - val_loss: 0.2854 - val_accuracy: 0.9190\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1142 - accuracy: 0.9654 - val_loss: 0.2693 - val_accuracy: 0.9238\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 19s 27ms/step - loss: 0.1177 - accuracy: 0.9644 - val_loss: 0.2707 - val_accuracy: 0.9238\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1131 - accuracy: 0.9653 - val_loss: 0.2608 - val_accuracy: 0.9262\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1173 - accuracy: 0.9648 - val_loss: 0.2566 - val_accuracy: 0.9286\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 15s 22ms/step - loss: 0.1142 - accuracy: 0.9652 - val_loss: 0.2581 - val_accuracy: 0.9286\n",
      "Epoch 20/100\n",
      "704/704 [==============================] - 18s 26ms/step - loss: 0.1142 - accuracy: 0.9655 - val_loss: 0.2501 - val_accuracy: 0.9286\n",
      "Epoch 21/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1129 - accuracy: 0.9656 - val_loss: 0.2500 - val_accuracy: 0.9310\n",
      "Epoch 22/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1142 - accuracy: 0.9659 - val_loss: 0.2504 - val_accuracy: 0.9286\n",
      "Epoch 23/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1137 - accuracy: 0.9655 - val_loss: 0.2445 - val_accuracy: 0.9310\n",
      "Epoch 24/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1147 - accuracy: 0.9655 - val_loss: 0.2404 - val_accuracy: 0.9310\n",
      "Epoch 25/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.1123 - accuracy: 0.9662 - val_loss: 0.2377 - val_accuracy: 0.9310\n",
      "Epoch 26/100\n",
      "704/704 [==============================] - 18s 26ms/step - loss: 0.1134 - accuracy: 0.9651 - val_loss: 0.2373 - val_accuracy: 0.9310\n",
      "Epoch 27/100\n",
      "704/704 [==============================] - 17s 25ms/step - loss: 0.1121 - accuracy: 0.9658 - val_loss: 0.2316 - val_accuracy: 0.9310\n",
      "Epoch 28/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1115 - accuracy: 0.9664 - val_loss: 0.2365 - val_accuracy: 0.9333\n",
      "Epoch 29/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1088 - accuracy: 0.9666 - val_loss: 0.2326 - val_accuracy: 0.9357\n",
      "Epoch 30/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.1140 - accuracy: 0.9654 - val_loss: 0.2237 - val_accuracy: 0.9333\n",
      "Epoch 31/100\n",
      "704/704 [==============================] - 17s 25ms/step - loss: 0.1151 - accuracy: 0.9654 - val_loss: 0.2167 - val_accuracy: 0.9357\n",
      "Epoch 32/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1132 - accuracy: 0.9655 - val_loss: 0.2183 - val_accuracy: 0.9357\n",
      "Epoch 33/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1137 - accuracy: 0.9657 - val_loss: 0.2227 - val_accuracy: 0.9357\n",
      "Epoch 34/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1116 - accuracy: 0.9658 - val_loss: 0.2143 - val_accuracy: 0.9381\n",
      "Epoch 35/100\n",
      "704/704 [==============================] - 20s 28ms/step - loss: 0.1131 - accuracy: 0.9659 - val_loss: 0.2167 - val_accuracy: 0.9357\n",
      "Epoch 36/100\n",
      "704/704 [==============================] - 19s 28ms/step - loss: 0.1118 - accuracy: 0.9662 - val_loss: 0.2053 - val_accuracy: 0.9357\n",
      "Epoch 37/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1116 - accuracy: 0.9664 - val_loss: 0.2081 - val_accuracy: 0.9405\n",
      "Epoch 38/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.1110 - accuracy: 0.9660 - val_loss: 0.2112 - val_accuracy: 0.9333\n",
      "Epoch 39/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1094 - accuracy: 0.9667 - val_loss: 0.2070 - val_accuracy: 0.9381\n",
      "Epoch 40/100\n",
      "704/704 [==============================] - 17s 25ms/step - loss: 0.1105 - accuracy: 0.9668 - val_loss: 0.1971 - val_accuracy: 0.9405\n",
      "Epoch 41/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1102 - accuracy: 0.9659 - val_loss: 0.2064 - val_accuracy: 0.9381\n",
      "Epoch 42/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1134 - accuracy: 0.9657 - val_loss: 0.1952 - val_accuracy: 0.9429\n",
      "Epoch 43/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1078 - accuracy: 0.9672 - val_loss: 0.1973 - val_accuracy: 0.9405\n",
      "Epoch 44/100\n",
      "704/704 [==============================] - 17s 25ms/step - loss: 0.1088 - accuracy: 0.9674 - val_loss: 0.1871 - val_accuracy: 0.9429\n",
      "Epoch 45/100\n",
      "704/704 [==============================] - 22s 31ms/step - loss: 0.1062 - accuracy: 0.9676 - val_loss: 0.2002 - val_accuracy: 0.9357\n",
      "Epoch 46/100\n",
      "704/704 [==============================] - 18s 26ms/step - loss: 0.1084 - accuracy: 0.9671 - val_loss: 0.1904 - val_accuracy: 0.9429\n",
      "Epoch 47/100\n",
      "704/704 [==============================] - 18s 26ms/step - loss: 0.1100 - accuracy: 0.9665 - val_loss: 0.1901 - val_accuracy: 0.9405\n",
      "Epoch 48/100\n",
      "704/704 [==============================] - 18s 26ms/step - loss: 0.1104 - accuracy: 0.9658 - val_loss: 0.1818 - val_accuracy: 0.9429\n",
      "Epoch 49/100\n",
      "704/704 [==============================] - 18s 26ms/step - loss: 0.1091 - accuracy: 0.9665 - val_loss: 0.1797 - val_accuracy: 0.9429\n",
      "Epoch 50/100\n",
      "704/704 [==============================] - 19s 27ms/step - loss: 0.1114 - accuracy: 0.9657 - val_loss: 0.1767 - val_accuracy: 0.9452\n",
      "Epoch 51/100\n",
      "704/704 [==============================] - 19s 27ms/step - loss: 0.1090 - accuracy: 0.9673 - val_loss: 0.1834 - val_accuracy: 0.9429\n",
      "Epoch 52/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.1070 - accuracy: 0.9671 - val_loss: 0.1816 - val_accuracy: 0.9429\n",
      "Epoch 53/100\n",
      "704/704 [==============================] - 17s 25ms/step - loss: 0.1089 - accuracy: 0.9669 - val_loss: 0.1786 - val_accuracy: 0.9429\n",
      "Epoch 54/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.1102 - accuracy: 0.9662 - val_loss: 0.1812 - val_accuracy: 0.9405\n",
      "Epoch 55/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1074 - accuracy: 0.9679 - val_loss: 0.1667 - val_accuracy: 0.9500\n",
      "Epoch 56/100\n",
      "704/704 [==============================] - 19s 27ms/step - loss: 0.1085 - accuracy: 0.9678 - val_loss: 0.1759 - val_accuracy: 0.9429\n",
      "Epoch 57/100\n",
      "704/704 [==============================] - 19s 27ms/step - loss: 0.1085 - accuracy: 0.9673 - val_loss: 0.1678 - val_accuracy: 0.9452\n",
      "Epoch 58/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.1060 - accuracy: 0.9674 - val_loss: 0.1717 - val_accuracy: 0.9452\n",
      "Epoch 59/100\n",
      "704/704 [==============================] - 18s 26ms/step - loss: 0.1092 - accuracy: 0.9666 - val_loss: 0.1755 - val_accuracy: 0.9500\n",
      "Epoch 60/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1089 - accuracy: 0.9671 - val_loss: 0.1678 - val_accuracy: 0.9476\n",
      "Epoch 61/100\n",
      "704/704 [==============================] - 19s 27ms/step - loss: 0.1072 - accuracy: 0.9671 - val_loss: 0.1627 - val_accuracy: 0.9476\n",
      "Epoch 62/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1071 - accuracy: 0.9674 - val_loss: 0.1560 - val_accuracy: 0.9476\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 18s 26ms/step - loss: 0.1090 - accuracy: 0.9666 - val_loss: 0.1608 - val_accuracy: 0.9476\n",
      "Epoch 64/100\n",
      "704/704 [==============================] - 17s 25ms/step - loss: 0.1046 - accuracy: 0.9679 - val_loss: 0.1584 - val_accuracy: 0.9500\n",
      "Epoch 65/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.1107 - accuracy: 0.9665 - val_loss: 0.1597 - val_accuracy: 0.9524\n",
      "Epoch 66/100\n",
      "704/704 [==============================] - 17s 25ms/step - loss: 0.1068 - accuracy: 0.9681 - val_loss: 0.1542 - val_accuracy: 0.9476\n",
      "Epoch 67/100\n",
      "704/704 [==============================] - 21s 29ms/step - loss: 0.1066 - accuracy: 0.9675 - val_loss: 0.1639 - val_accuracy: 0.9524\n",
      "Epoch 68/100\n",
      "704/704 [==============================] - 19s 28ms/step - loss: 0.1076 - accuracy: 0.9674 - val_loss: 0.1538 - val_accuracy: 0.9571\n",
      "Epoch 69/100\n",
      "704/704 [==============================] - 19s 27ms/step - loss: 0.1047 - accuracy: 0.9679 - val_loss: 0.1578 - val_accuracy: 0.9548\n",
      "Epoch 70/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1059 - accuracy: 0.9683 - val_loss: 0.1615 - val_accuracy: 0.9524\n",
      "Epoch 71/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.1087 - accuracy: 0.9676 - val_loss: 0.1546 - val_accuracy: 0.9524\n",
      "Epoch 72/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1036 - accuracy: 0.9681 - val_loss: 0.1503 - val_accuracy: 0.9524\n",
      "Epoch 73/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1076 - accuracy: 0.9672 - val_loss: 0.1453 - val_accuracy: 0.9548\n",
      "Epoch 74/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.1090 - accuracy: 0.9672 - val_loss: 0.1443 - val_accuracy: 0.9548\n",
      "Epoch 75/100\n",
      "704/704 [==============================] - 20s 29ms/step - loss: 0.1078 - accuracy: 0.9677 - val_loss: 0.1449 - val_accuracy: 0.9548\n",
      "Epoch 76/100\n",
      "704/704 [==============================] - 19s 27ms/step - loss: 0.1067 - accuracy: 0.9668 - val_loss: 0.1458 - val_accuracy: 0.9548\n",
      "Epoch 77/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.1047 - accuracy: 0.9677 - val_loss: 0.1499 - val_accuracy: 0.9524\n",
      "Epoch 78/100\n",
      "704/704 [==============================] - 18s 26ms/step - loss: 0.1066 - accuracy: 0.9673 - val_loss: 0.1478 - val_accuracy: 0.9524\n",
      "Epoch 79/100\n",
      "704/704 [==============================] - 21s 30ms/step - loss: 0.1011 - accuracy: 0.9684 - val_loss: 0.1508 - val_accuracy: 0.9548\n",
      "Epoch 80/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.1059 - accuracy: 0.9679 - val_loss: 0.1435 - val_accuracy: 0.9548\n",
      "Epoch 81/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1031 - accuracy: 0.9680 - val_loss: 0.1386 - val_accuracy: 0.9571\n",
      "Epoch 82/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1058 - accuracy: 0.9676 - val_loss: 0.1434 - val_accuracy: 0.9571\n",
      "Epoch 83/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1066 - accuracy: 0.9676 - val_loss: 0.1410 - val_accuracy: 0.9571\n",
      "Epoch 84/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1032 - accuracy: 0.9685 - val_loss: 0.1355 - val_accuracy: 0.9571\n",
      "Epoch 85/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.1058 - accuracy: 0.9676 - val_loss: 0.1362 - val_accuracy: 0.9595\n",
      "Epoch 86/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1043 - accuracy: 0.9677 - val_loss: 0.1450 - val_accuracy: 0.9595\n",
      "Epoch 87/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1033 - accuracy: 0.9679 - val_loss: 0.1350 - val_accuracy: 0.9643\n",
      "Epoch 88/100\n",
      "704/704 [==============================] - 18s 26ms/step - loss: 0.1056 - accuracy: 0.9682 - val_loss: 0.1353 - val_accuracy: 0.9571\n",
      "Epoch 89/100\n",
      "704/704 [==============================] - 18s 26ms/step - loss: 0.1062 - accuracy: 0.9669 - val_loss: 0.1396 - val_accuracy: 0.9595\n",
      "Epoch 90/100\n",
      "704/704 [==============================] - 19s 27ms/step - loss: 0.1074 - accuracy: 0.9679 - val_loss: 0.1315 - val_accuracy: 0.9619\n",
      "Epoch 91/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1022 - accuracy: 0.9689 - val_loss: 0.1385 - val_accuracy: 0.9595\n",
      "Epoch 92/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1049 - accuracy: 0.9676 - val_loss: 0.1279 - val_accuracy: 0.9619\n",
      "Epoch 93/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1031 - accuracy: 0.9684 - val_loss: 0.1360 - val_accuracy: 0.9619\n",
      "Epoch 94/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1033 - accuracy: 0.9681 - val_loss: 0.1278 - val_accuracy: 0.9643\n",
      "Epoch 95/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.1029 - accuracy: 0.9684 - val_loss: 0.1295 - val_accuracy: 0.9619\n",
      "Epoch 96/100\n",
      "704/704 [==============================] - 17s 25ms/step - loss: 0.1069 - accuracy: 0.9671 - val_loss: 0.1251 - val_accuracy: 0.9595\n",
      "Epoch 97/100\n",
      "704/704 [==============================] - 17s 24ms/step - loss: 0.1049 - accuracy: 0.9681 - val_loss: 0.1293 - val_accuracy: 0.9643\n",
      "Epoch 98/100\n",
      "704/704 [==============================] - 16s 23ms/step - loss: 0.1048 - accuracy: 0.9676 - val_loss: 0.1222 - val_accuracy: 0.9595\n",
      "Epoch 99/100\n",
      "704/704 [==============================] - 18s 25ms/step - loss: 0.1054 - accuracy: 0.9679 - val_loss: 0.1195 - val_accuracy: 0.9643\n",
      "Epoch 100/100\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 0.1057 - accuracy: 0.9671 - val_loss: 0.1266 - val_accuracy: 0.9643\n",
      "model_3 재학습 1번 완료\n",
      "model_3 저장\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiyeong/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/home/jiyeong/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:430: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import pickle\n",
    "import joblib\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Label 형변환용 함수\n",
    "def label_to_numeric(x):\n",
    "        if x=='normal':  return 0\n",
    "        if x=='out':     return 1\n",
    "        if x=='in':      return 2\n",
    "        if x=='noise':   return 3\n",
    "        if x=='other':   return 4\n",
    "\n",
    "def numeric_to_label(x):\n",
    "        if x==0:   return 'normal'\n",
    "        if x==1:   return 'out'\n",
    "        if x==2:   return 'in'\n",
    "        if x==3:   return 'noise'\n",
    "        if x==4:   return 'other'\n",
    "\n",
    "def pred_ensemble_1(pred_1, pred_2, proba_1, proba_2):\n",
    "    \n",
    "    pred = []\n",
    "    proba = []\n",
    "    for i in range(len(pred_1)):\n",
    "        if pred_1[i] == pred_2[i]:\n",
    "            pred.append(pred_1[i])\n",
    "            proba.append(max(max(proba_1[i]),max(proba_2[i])))\n",
    "        elif (pred_1[i] == 'in' or pred_1[i] == 'out') and (pred_2[i] != 'in' and pred_2[i] != 'out'):\n",
    "            pred.append(pred_1[i])\n",
    "            proba.append(max(proba_1[i]))\n",
    "        elif (pred_2[i] == 'in' or pred_2[i] == 'out') and (pred_1[i] != 'in' and pred_1[i] != 'out'):\n",
    "            pred.append(pred_2[i])\n",
    "            proba.append(max(proba_2[i]))\n",
    "        else:\n",
    "            if max(proba_1[i]) > max(proba_2[i]):\n",
    "                pred.append(pred_1[i])\n",
    "                proba.append(max(proba_1[i]))\n",
    "            else:\n",
    "                pred.append(pred_2[i])\n",
    "                proba.append(max(proba_2[i]))\n",
    "                \n",
    "    return pred, proba\n",
    "\n",
    "def pred_ensemble_2(pred_1, pred_2, proba_1, proba_2):\n",
    "    \n",
    "    pred = []\n",
    "    for i in range(len(pred_1)):\n",
    "        if pred_1[i] == pred_2[i]:\n",
    "            pred.append(pred_1[i])\n",
    "        elif (pred_1[i] == 'in' or pred_1[i] == 'out') and (pred_2[i] != 'in' and pred_2[i] != 'out'):\n",
    "            pred.append(pred_1[i])\n",
    "        elif (pred_2[i] == 'in' or pred_2[i] == 'out') and (pred_1[i] != 'in' and pred_1[i] != 'out'):\n",
    "            pred.append(pred_2[i])\n",
    "        else:\n",
    "            if proba_1[i] > proba_2[i]:\n",
    "                pred.append(pred_1[i])\n",
    "            else:\n",
    "                pred.append(pred_2[i])\n",
    "    return pred\n",
    "\n",
    "##############################################################################################################################\n",
    "##############################################################################################################################\n",
    "\n",
    "# 1. 데이터 전처리\n",
    "# data loding - 컬럼별 정규화 데이터셋\n",
    "data = pd.read_csv('train/train.csv')\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data[data.columns[1:]])\n",
    "data[data.columns[1:]] = scaler.transform(data[data.columns[1:]])\n",
    "file_name = 'model/minmaxscaler.pkl'\n",
    "joblib.dump(scaler, file_name)\n",
    "\n",
    "# 전체 데이터셋을 이용한 train set\n",
    "X = data[data.columns[1:]]\n",
    "y = data[data.columns[0]]\n",
    "\n",
    "sm = SMOTE(random_state=100)\n",
    "X_resampled_all_1, y_resampled_all_1 = sm.fit_sample(X,y)\n",
    "sm = SMOTE(random_state=10)\n",
    "X_resampled_all_2, y_resampled_all_2 = sm.fit_sample(X,y)\n",
    "\n",
    "# test set은 각 라벨별 최소한도(검증의 역할을 할 수 있는 범위에서)로 추출\n",
    "data_0 = data.iloc[np.where(data['leaktype'] == 'out')].sample(n=100, random_state=100)\n",
    "data.drop(data_0.index, inplace=True)\n",
    "data_1 = data.iloc[np.where(data['leaktype'] == 'in')].sample(n=100, random_state=100)\n",
    "data.drop(data_1.index, inplace=True)\n",
    "data_2 = data.iloc[np.where(data['leaktype'] == 'normal')].sample(n=20, random_state=100)\n",
    "data.drop(data_2.index, inplace=True)\n",
    "data_3 = data.iloc[np.where(data['leaktype'] == 'other')].sample(n=100, random_state=100)\n",
    "data.drop(data_3.index, inplace=True)\n",
    "data_4 = data.iloc[np.where(data['leaktype'] == 'noise')].sample(n=100, random_state=100)\n",
    "data.drop(data_4.index, inplace=True)\n",
    "\n",
    "data_test = pd.concat([data_0, data_1], axis=0)\n",
    "data_test = pd.concat([data_test, data_2], axis=0)\n",
    "data_test = pd.concat([data_test, data_3], axis=0)\n",
    "data_test = pd.concat([data_test, data_4], axis=0)\n",
    "\n",
    "X_train = data[data.columns[1:]]\n",
    "y_train = data[data.columns[0]]\n",
    "X_test = data_test[data_test.columns[1:]]\n",
    "y_test = data_test[data_test.columns[0]]\n",
    "\n",
    "sm = SMOTE(random_state=100)\n",
    "X_resampled, y_resampled = sm.fit_sample(X_train,y_train)\n",
    "\n",
    "X_train = copy.deepcopy(X_resampled)\n",
    "y_train = copy.deepcopy(y_resampled)\n",
    "\n",
    "# data loding - 로우별 정규화 데이터셋\n",
    "data = pd.read_csv('train/train.csv')\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data[data.columns[1:]].T)\n",
    "data[data.columns[1:]] = scaler.transform(data[data.columns[1:]].T).T\n",
    "\n",
    "# 전체 데이터셋을 이용한 train set\n",
    "X_tsc = data[data.columns[1:]]\n",
    "y_tsc = data[data.columns[0]]\n",
    "\n",
    "sm = SMOTE(random_state=100)\n",
    "X_resampled_tsc_all_1, y_resampled_tsc_all_1 = sm.fit_sample(X_tsc,y_tsc)\n",
    "sm = SMOTE(random_state=10)\n",
    "X_resampled_tsc_all_2, y_resampled_tsc_all_2 = sm.fit_sample(X_tsc,y_tsc)\n",
    "\n",
    "# test set은 각 라벨별 최소한도(검증의 역할을 할 수 있는 범위에서)로 추출\n",
    "data_0 = data.iloc[np.where(data['leaktype'] == 'out')].sample(n=100, random_state=100)\n",
    "data.drop(data_0.index, inplace=True)\n",
    "data_1 = data.iloc[np.where(data['leaktype'] == 'in')].sample(n=100, random_state=100)\n",
    "data.drop(data_1.index, inplace=True)\n",
    "data_2 = data.iloc[np.where(data['leaktype'] == 'normal')].sample(n=20, random_state=100)\n",
    "data.drop(data_2.index, inplace=True)\n",
    "data_3 = data.iloc[np.where(data['leaktype'] == 'other')].sample(n=100, random_state=100)\n",
    "data.drop(data_3.index, inplace=True)\n",
    "data_4 = data.iloc[np.where(data['leaktype'] == 'noise')].sample(n=100, random_state=100)\n",
    "data.drop(data_4.index, inplace=True)\n",
    "\n",
    "data_test = pd.concat([data_0, data_1], axis=0)\n",
    "data_test = pd.concat([data_test, data_2], axis=0)\n",
    "data_test = pd.concat([data_test, data_3], axis=0)\n",
    "data_test = pd.concat([data_test, data_4], axis=0)\n",
    "\n",
    "X_train_tsc = data[data.columns[1:]]\n",
    "y_train_tsc = data[data.columns[0]]\n",
    "X_test_tsc = data_test[data_test.columns[1:]]\n",
    "y_test_tsc = data_test[data_test.columns[0]]\n",
    "\n",
    "sm = SMOTE(random_state=100)\n",
    "X_resampled_tsc, y_resampled_tsc = sm.fit_sample(X_train_tsc,y_train_tsc)\n",
    "\n",
    "X_train_tsc = copy.deepcopy(X_resampled_tsc)\n",
    "y_train_tsc = copy.deepcopy(y_resampled_tsc)\n",
    "\n",
    "##############################################################################################################################\n",
    "##############################################################################################################################\n",
    "\n",
    "# 2. ML모델(KNN, XGB, RF 모델 앙상블)\n",
    "KNN = KNeighborsClassifier(n_jobs=-1)\n",
    "RF = RandomForestClassifier(n_jobs=-1, random_state=5023)\n",
    "XGB = XGBClassifier(base_score=0.5, booster='gbtree',colsample_bylevel=1,colsample_bynode=1,colsample_bytree=1, gamma=0,\n",
    "                    gpu_id=-1, importance_type='gain',interaction_constraints='',learning_rate=0.300000012,max_delta_step=0,\n",
    "                    max_depth=6,min_child_weight=1,monotone_constraints='()',n_estimators=100,n_jobs=-1,num_parallel_tree=1,\n",
    "                    objective='multi:softprob',random_state=5023, reg_alpha=0,reg_lambda=1, scale_pos_weight=None,\n",
    "                    subsample=1, tree_method='auto',validate_parameters=1,verbosity=0)\n",
    "\n",
    "votingC = VotingClassifier(estimators=[('knn', KNN), ('rf', RF), ('xgboost', XGB)], n_jobs=-1, voting='soft')\n",
    "print(\"Voting Classifier 학습중...\")\n",
    "votingC.fit(X_resampled_all_1, y_resampled_all_1)\n",
    "\n",
    "votingCPickle = open('model/votingC.h5', 'wb')\n",
    "pickle.dump(votingC, votingCPickle)\n",
    "print(\"Voting Classifier 저장\\n\")\n",
    "\n",
    "##############################################################################################################################\n",
    "##############################################################################################################################\n",
    "\n",
    "# 3. DL모델(1dconv)\n",
    "# 데이터 전처리(DL)\n",
    "\n",
    "# 컬럼 정규화, train/test data set\n",
    "X_train_dl = X_train.values\n",
    "X_test_dl = X_test.values\n",
    "X_train_dl = np.reshape(X_train_dl, (X_train_dl.shape[0],X_train_dl.shape[1],1), order='C')\n",
    "X_test_dl = np.reshape(X_test_dl, (X_test_dl.shape[0],X_test_dl.shape[1],1), order='C')\n",
    "\n",
    "y_train_dl = pd.DataFrame(y_train)['leaktype'].apply(label_to_numeric)\n",
    "y_test_dl = pd.DataFrame(y_test)['leaktype'].apply(label_to_numeric)\n",
    "y_train_dl = to_categorical(y_train_dl, num_classes = 5)\n",
    "y_test_dl = to_categorical(y_test_dl, num_classes = 5)\n",
    "\n",
    "# 컬럼 정규화, 전체 data set 1\n",
    "X_train_dl_all_1 = X_resampled_all_1.values\n",
    "X_train_dl_all_1 = np.reshape(X_train_dl_all_1, (X_train_dl_all_1.shape[0],X_train_dl_all_1.shape[1],1), order='C')\n",
    "\n",
    "y_train_dl_all_1 = pd.DataFrame(y_resampled_all_1)['leaktype'].apply(label_to_numeric)\n",
    "y_train_dl_all_1 = to_categorical(y_train_dl_all_1, num_classes = 5)\n",
    "\n",
    "# 컬럼 정규화, 전체 data set 2\n",
    "X_train_dl_all_2 = X_resampled_all_2.values\n",
    "X_train_dl_all_2 = np.reshape(X_train_dl_all_2, (X_train_dl_all_2.shape[0],X_train_dl_all_2.shape[1],1), order='C')\n",
    "\n",
    "y_train_dl_all_2 = pd.DataFrame(y_resampled_all_2)['leaktype'].apply(label_to_numeric)\n",
    "y_train_dl_all_2 = to_categorical(y_train_dl_all_2, num_classes = 5)\n",
    "\n",
    "# 로우 정규화, train/test data set\n",
    "X_train_dl_tsc = X_train_tsc.values\n",
    "X_test_dl_tsc = X_test_tsc.values\n",
    "X_train_dl_tsc = np.reshape(X_train_dl_tsc, (X_train_dl_tsc.shape[0],X_train_dl_tsc.shape[1],1), order='C')\n",
    "X_test_dl_tsc = np.reshape(X_test_dl_tsc, (X_test_dl_tsc.shape[0],X_test_dl_tsc.shape[1],1), order='C')\n",
    "\n",
    "y_train_dl_tsc = pd.DataFrame(y_train_tsc)['leaktype'].apply(label_to_numeric)\n",
    "y_test_dl_tsc = pd.DataFrame(y_test_tsc)['leaktype'].apply(label_to_numeric)\n",
    "y_train_dl_tsc = to_categorical(y_train_dl_tsc, num_classes = 5)\n",
    "y_test_dl_tsc = to_categorical(y_test_dl_tsc, num_classes = 5)\n",
    "\n",
    "# 로우 정규화, 전체 data set 1\n",
    "X_train_dl_tsc_all_1 = X_resampled_tsc_all_1.values\n",
    "X_train_dl_tsc_all_1 = np.reshape(X_train_dl_tsc_all_1, (X_train_dl_tsc_all_1.shape[0],X_train_dl_tsc_all_1.shape[1],1), order='C')\n",
    "\n",
    "y_train_dl_tsc_all_1 = pd.DataFrame(y_resampled_tsc_all_1)['leaktype'].apply(label_to_numeric)\n",
    "y_train_dl_tsc_all_1 = to_categorical(y_train_dl_tsc_all_1, num_classes = 5)\n",
    "\n",
    "# 로우 정규화, 전체 data set 2\n",
    "X_train_dl_tsc_all_2 = X_resampled_tsc_all_2.values\n",
    "X_train_dl_tsc_all_2 = np.reshape(X_train_dl_tsc_all_2, (X_train_dl_tsc_all_2.shape[0],X_train_dl_tsc_all_2.shape[1],1), order='C')\n",
    "\n",
    "y_train_dl_tsc_all_2 = pd.DataFrame(y_resampled_tsc_all_2)['leaktype'].apply(label_to_numeric)\n",
    "y_train_dl_tsc_all_2 = to_categorical(y_train_dl_tsc_all_2, num_classes = 5)\n",
    "\n",
    "##############################################################################################################################\n",
    "##############################################################################################################################\n",
    "\n",
    "batch_size = 128\n",
    "Epoch = 1000\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=20, min_lr=0.00001)\n",
    "earlystopper = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", mode='max', patience=75, verbose=1)\n",
    "\n",
    "# model_1(컬럼 정규화 데이터)\n",
    "\n",
    "model_1=tf.keras.models.Sequential()\n",
    "model_1.add(tf.keras.layers.Conv1D(64, 9, padding = 'causal', activation='relu', strides=1, input_shape=X_train_dl.shape[-2:]))\n",
    "model_1.add(tf.keras.layers.MaxPooling1D(padding = 'valid'))\n",
    "model_1.add(tf.keras.layers.Dropout(0.35))\n",
    "model_1.add(tf.keras.layers.Conv1D(128, 9, padding = 'causal', activation='relu', strides=1))\n",
    "model_1.add(tf.keras.layers.MaxPooling1D(padding = 'valid'))\n",
    "model_1.add(tf.keras.layers.Dropout(0.35))\n",
    "model_1.add(tf.keras.layers.Conv1D(256, 9, padding = 'causal', activation='relu', strides=1))\n",
    "model_1.add(tf.keras.layers.MaxPooling1D(padding = 'valid'))\n",
    "model_1.add(tf.keras.layers.Dropout(0.35))\n",
    "model_1.add(tf.keras.layers.Conv1D(256, 9, padding = 'causal', activation='relu', strides=1))\n",
    "model_1.add(tf.keras.layers.MaxPooling1D(padding = 'valid'))\n",
    "model_1.add(tf.keras.layers.Dropout(0.35))\n",
    "model_1.add(tf.keras.layers.Conv1D(128, 9, padding = 'causal', activation='relu', strides=1))\n",
    "model_1.add(tf.keras.layers.MaxPooling1D(padding = 'valid'))\n",
    "model_1.add(tf.keras.layers.Dropout(0.35))\n",
    "model_1.add(tf.keras.layers.Conv1D(64, 9, padding = 'causal', activation='relu', strides=1))\n",
    "model_1.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model_1.add(tf.keras.layers.Dropout(0.35))\n",
    "model_1.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model_1.add(tf.keras.layers.Dropout(0.35))\n",
    "model_1.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_1.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_1.fit(X_train_dl,y_train_dl,validation_data=(X_test_dl,y_test_dl),epochs=Epoch,batch_size=batch_size,\n",
    "            callbacks=[earlystopper, reduce_lr])\n",
    "loss_ = model_1.evaluate(X_test_dl,y_test_dl)\n",
    "print(\"model_1 loss :\", loss_)\n",
    "\n",
    "# 재학습1\n",
    "model_1.fit(X_train_dl_all_1,y_train_dl_all_1,validation_data=(X_test_dl,y_test_dl), epochs=100, batch_size=batch_size)\n",
    "print(\"model_1 재학습 1번 완료\")\n",
    "\n",
    "# 재학습2\n",
    "model_1.fit(X_train_dl_all_2,y_train_dl_all_2,validation_data=(X_test_dl,y_test_dl), epochs=100, batch_size=batch_size)\n",
    "print(\"model_1 재학습 2번 완료\")\n",
    "\n",
    "model_1.save('model/model_1.h5') # model_1 200번 재학습\n",
    "print(\"model_1 저장\\n\")\n",
    "\n",
    "# model_2(로우 정규화 데이터)\n",
    "\n",
    "model_2=tf.keras.models.Sequential()\n",
    "model_2.add(tf.keras.layers.Conv1D(64, 9, padding = 'causal', activation='relu', strides=1, input_shape=X_train_dl_tsc.shape[-2:]))\n",
    "model_2.add(tf.keras.layers.MaxPooling1D(padding = 'valid'))\n",
    "model_2.add(tf.keras.layers.Dropout(0.35))\n",
    "model_2.add(tf.keras.layers.Conv1D(128, 9, padding = 'causal', activation='relu', strides=1))\n",
    "model_2.add(tf.keras.layers.MaxPooling1D(padding = 'valid'))\n",
    "model_2.add(tf.keras.layers.Dropout(0.35))\n",
    "model_2.add(tf.keras.layers.Conv1D(256, 9, padding = 'causal', activation='relu', strides=1))\n",
    "model_2.add(tf.keras.layers.MaxPooling1D(padding = 'valid'))\n",
    "model_2.add(tf.keras.layers.Dropout(0.35))\n",
    "model_2.add(tf.keras.layers.Conv1D(256, 9, padding = 'causal', activation='relu', strides=1))\n",
    "model_2.add(tf.keras.layers.MaxPooling1D(padding = 'valid'))\n",
    "model_2.add(tf.keras.layers.Dropout(0.35))\n",
    "model_2.add(tf.keras.layers.Conv1D(128, 9, padding = 'causal', activation='relu', strides=1))\n",
    "model_2.add(tf.keras.layers.MaxPooling1D(padding = 'valid'))\n",
    "model_2.add(tf.keras.layers.Dropout(0.35))\n",
    "model_2.add(tf.keras.layers.Conv1D(64, 9, padding = 'causal', activation='relu', strides=1))\n",
    "model_2.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model_2.add(tf.keras.layers.Dropout(0.35))\n",
    "model_2.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model_2.add(tf.keras.layers.Dropout(0.35))\n",
    "model_2.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_2.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_2.fit(X_train_dl_tsc,y_train_dl_tsc,validation_data=(X_test_dl_tsc,y_test_dl_tsc),epochs=Epoch,batch_size=batch_size,\n",
    "            callbacks=[earlystopper, reduce_lr])\n",
    "loss_ = model_2.evaluate(X_test_dl_tsc,y_test_dl_tsc)\n",
    "print(\"model_2 loss :\", loss_)\n",
    "\n",
    "# 재학습1\n",
    "model_2.fit(X_train_dl_tsc_all_1,y_train_dl_tsc_all_1,validation_data=(X_test_dl_tsc,y_test_dl_tsc), epochs=100, batch_size=batch_size)\n",
    "print(\"model_2 재학습 1번 완료\")\n",
    "\n",
    "# 재학습2\n",
    "model_2.fit(X_train_dl_tsc_all_2,y_train_dl_tsc_all_2,validation_data=(X_test_dl_tsc,y_test_dl_tsc), epochs=100, batch_size=batch_size)\n",
    "print(\"model_2 재학습 2번 완료\")\n",
    "\n",
    "model_2.save('model/model_2.h5') # model_2 200번 재학습\n",
    "print(\"model_2 저장\\n\")\n",
    "\n",
    "# model_3(로우 정규화 데이터, class_weight적용)\n",
    "d_class_weights = {0: 1, 1: 2, 2: 2, 3: 1.5, 4: 1.5}\n",
    "\n",
    "model_3=tf.keras.models.Sequential()\n",
    "model_3.add(tf.keras.layers.Conv1D(64, 9, padding = 'causal', activation='relu', strides=1, input_shape=X_train_dl_tsc.shape[-2:]))\n",
    "model_3.add(tf.keras.layers.MaxPooling1D(padding = 'valid'))\n",
    "model_3.add(tf.keras.layers.Dropout(0.35))\n",
    "model_3.add(tf.keras.layers.Conv1D(128, 9, padding = 'causal', activation='relu', strides=1))\n",
    "model_3.add(tf.keras.layers.MaxPooling1D(padding = 'valid'))\n",
    "model_3.add(tf.keras.layers.Dropout(0.35))\n",
    "model_3.add(tf.keras.layers.Conv1D(256, 9, padding = 'causal', activation='relu', strides=1))\n",
    "model_3.add(tf.keras.layers.MaxPooling1D(padding = 'valid'))\n",
    "model_3.add(tf.keras.layers.Dropout(0.35))\n",
    "model_3.add(tf.keras.layers.Conv1D(256, 9, padding = 'causal', activation='relu', strides=1))\n",
    "model_3.add(tf.keras.layers.MaxPooling1D(padding = 'valid'))\n",
    "model_3.add(tf.keras.layers.Dropout(0.35))\n",
    "model_3.add(tf.keras.layers.Conv1D(128, 9, padding = 'causal', activation='relu', strides=1))\n",
    "model_3.add(tf.keras.layers.MaxPooling1D(padding = 'valid'))\n",
    "model_3.add(tf.keras.layers.Dropout(0.35))\n",
    "model_3.add(tf.keras.layers.Conv1D(64, 9, padding = 'causal', activation='relu', strides=1))\n",
    "model_3.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model_3.add(tf.keras.layers.Dropout(0.35))\n",
    "model_3.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model_3.add(tf.keras.layers.Dropout(0.35))\n",
    "model_3.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_3.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_3.fit(X_train_dl_tsc,y_train_dl_tsc,validation_data=(X_test_dl_tsc,y_test_dl_tsc),epochs=Epoch,batch_size=batch_size,\n",
    "            class_weight=d_class_weights, callbacks=[earlystopper, reduce_lr])\n",
    "loss_ = model_3.evaluate(X_test_dl_tsc,y_test_dl_tsc)\n",
    "print(\"model_3 loss :\", loss_)\n",
    "\n",
    "# 재학습1\n",
    "model_3.fit(X_train_dl_tsc_all_1,y_train_dl_tsc_all_1,validation_data=(X_test_dl_tsc,y_test_dl_tsc), epochs=100, batch_size=batch_size)\n",
    "print(\"model_3 재학습 1번 완료\")\n",
    "\n",
    "# model_3은 1차 재학습 단계에서 충분히 학습하여(편향적인 test set에 대하여 class_weight가 영향을 준것으로 예상) 2차는 진행하지 않음\n",
    "\n",
    "model_3.save('model/model_3.h5') # model_3 100번 재학습\n",
    "print(\"model_3 저장\\n\")\n",
    "\n",
    "##############################################################################################################################\n",
    "##############################################################################################################################\n",
    "\n",
    "# 4. Inference - test set 예측 및 submission 생성\n",
    "votingCPickle = open('model/votingC.h5', 'rb')\n",
    "votingC = pickle.load(votingCPickle)\n",
    "model_1 = tf.keras.models.load_model('model/model_1.h5')\n",
    "model_2 = tf.keras.models.load_model('model/model_2.h5')\n",
    "model_3 = tf.keras.models.load_model('model/model_3.h5')\n",
    "\n",
    "# data loding\n",
    "test = pd.read_csv('test/test.csv')\n",
    "\n",
    "# 컬럼 정규화 test set\n",
    "file_name = 'model/minmaxscaler.pkl'\n",
    "scaler = joblib.load(file_name)\n",
    "test[test.columns[1:]] = scaler.transform(test[test.columns[1:]])\n",
    "X_submission_1 = test[test.columns[1:]]\n",
    "\n",
    "# 로우 정규화 test set\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(test[test.columns[1:]].T)\n",
    "test[test.columns[1:]] = scaler.transform(test[test.columns[1:]].T).T\n",
    "X_submission_2 = test[test.columns[1:]]\n",
    "\n",
    "# 데이터 전처리 및 predict\n",
    "# votingC (컬럼정규화)\n",
    "y_pred_votingC = votingC.predict(X_submission_1)\n",
    "y_proba_votingC = votingC.predict_proba(X_submission_1)\n",
    "\n",
    "# DL 입력용 전처리과정(votingC 모델은 컬럼이름이 필요해서 먼저처리함)\n",
    "X_submission_1 = X_submission_1.values\n",
    "X_submission_2 = X_submission_2.values\n",
    "\n",
    "# model_1 (컬럼정규화)\n",
    "X_submission_dl_1 = np.reshape(X_submission_1, (X_submission_1.shape[0],X_submission_1.shape[1],1), order='C')\n",
    "y_pred_dl_1 = model_1.predict_classes(X_submission_dl_1)\n",
    "y_pred_dl_1 = pd.DataFrame(y_pred_dl_1)[0].apply(numeric_to_label)\n",
    "y_proba_dl_1 = model_1.predict_proba(X_submission_dl_1)\n",
    "\n",
    "# model_2 (로우정규화)\n",
    "X_submission_dl_2 = np.reshape(X_submission_2, (X_submission_2.shape[0],X_submission_2.shape[1],1), order='C')\n",
    "y_pred_dl_2 = model_2.predict_classes(X_submission_dl_2)\n",
    "y_pred_dl_2 = pd.DataFrame(y_pred_dl_2)[0].apply(numeric_to_label)\n",
    "y_proba_dl_2 = model_2.predict_proba(X_submission_dl_2)\n",
    "\n",
    "# model_3 (로우정규화)\n",
    "X_submission_dl_3 = np.reshape(X_submission_2, (X_submission_2.shape[0],X_submission_2.shape[1],1), order='C')\n",
    "y_pred_dl_3 = model_3.predict_classes(X_submission_dl_3)\n",
    "y_pred_dl_3 = pd.DataFrame(y_pred_dl_3)[0].apply(numeric_to_label)\n",
    "y_proba_dl_3 = model_3.predict_proba(X_submission_dl_3)\n",
    "\n",
    "y_pred_ensemble_1, y_proba_ensemble_1 = pred_ensemble_1(y_pred_dl_1, y_pred_dl_2, y_proba_dl_1, y_proba_dl_2)\n",
    "y_pred_ensemble_2, y_proba_ensemble_2 = pred_ensemble_1(y_pred_dl_3, y_pred_votingC, y_proba_dl_3, y_proba_votingC)\n",
    "predictions = pred_ensemble_2(y_pred_ensemble_1, y_pred_ensemble_2, y_proba_ensemble_1, y_proba_ensemble_2)\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "sorter = list(sample_submission['id'])\n",
    "pred_df = pd.concat([test['id'], pd.DataFrame(predictions)],axis=1)\n",
    "resdf = pred_df.set_index('id')\n",
    "resdf.rename(columns={0:'leaktype'}, inplace=True)\n",
    "result = resdf.loc[sorter].reset_index()\n",
    "result.to_csv(\"submission/submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4337eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loding\n",
    "test = pd.read_csv('1.누수감지데이터-통합(leaks-all).csv')\n",
    "test = test[test.columns[5:-20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1514cbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "file_name = 'model/minmaxscaler.pkl'\n",
    "scaler = joblib.load(file_name)\n",
    "test[test.columns[1:]] = scaler.transform(test[test.columns[1:]])\n",
    "X_submission_1 = test[test.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33e5d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loding\n",
    "test = pd.read_csv('1.누수감지데이터-통합(leaks-all).csv')\n",
    "test = test[test.columns[5:-20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0038b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로우 정규화 test set\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(test[test.columns[1:]].T)\n",
    "test[test.columns[1:]] = scaler.transform(test[test.columns[1:]].T).T\n",
    "X_submission_2 = test[test.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "063e093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiyeong/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/home/jiyeong/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:430: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 및 predict\n",
    "# votingC (컬럼정규화)\n",
    "y_pred_votingC = votingC.predict(X_submission_1)\n",
    "y_proba_votingC = votingC.predict_proba(X_submission_1)\n",
    "\n",
    "# DL 입력용 전처리과정(votingC 모델은 컬럼이름이 필요해서 먼저처리함)\n",
    "X_submission_1 = X_submission_1.values\n",
    "X_submission_2 = X_submission_2.values\n",
    "\n",
    "# model_1 (컬럼정규화)\n",
    "X_submission_dl_1 = np.reshape(X_submission_1, (X_submission_1.shape[0],X_submission_1.shape[1],1), order='C')\n",
    "y_pred_dl_1 = model_1.predict_classes(X_submission_dl_1)\n",
    "y_pred_dl_1 = pd.DataFrame(y_pred_dl_1)[0].apply(numeric_to_label)\n",
    "y_proba_dl_1 = model_1.predict_proba(X_submission_dl_1)\n",
    "\n",
    "# model_2 (로우정규화)\n",
    "X_submission_dl_2 = np.reshape(X_submission_2, (X_submission_2.shape[0],X_submission_2.shape[1],1), order='C')\n",
    "y_pred_dl_2 = model_2.predict_classes(X_submission_dl_2)\n",
    "y_pred_dl_2 = pd.DataFrame(y_pred_dl_2)[0].apply(numeric_to_label)\n",
    "y_proba_dl_2 = model_2.predict_proba(X_submission_dl_2)\n",
    "\n",
    "# model_3 (로우정규화)\n",
    "X_submission_dl_3 = np.reshape(X_submission_2, (X_submission_2.shape[0],X_submission_2.shape[1],1), order='C')\n",
    "y_pred_dl_3 = model_3.predict_classes(X_submission_dl_3)\n",
    "y_pred_dl_3 = pd.DataFrame(y_pred_dl_3)[0].apply(numeric_to_label)\n",
    "y_proba_dl_3 = model_3.predict_proba(X_submission_dl_3)\n",
    "\n",
    "y_pred_ensemble_1, y_proba_ensemble_1 = pred_ensemble_1(y_pred_dl_1, y_pred_dl_2, y_proba_dl_1, y_proba_dl_2)\n",
    "y_pred_ensemble_2, y_proba_ensemble_2 = pred_ensemble_1(y_pred_dl_3, y_pred_votingC, y_proba_dl_3, y_proba_votingC)\n",
    "predictions = pred_ensemble_2(y_pred_ensemble_1, y_pred_ensemble_2, y_proba_ensemble_1, y_proba_ensemble_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40343f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5784623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.94, 0.93615042725311)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_kn = round(accuracy_score(test[test.columns[0]], predictions), 2)\n",
    "f1_kn = f1_score(test[test.columns[0]], predictions, average='macro')\n",
    "acc_kn, f1_kn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25552664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
